{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear Models\n",
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features shape: (280, 1280)\n",
      "train labels shape: (280,)\n"
     ]
    }
   ],
   "source": [
    "# load the data sets, train set\n",
    "with np.load(\"/Users/Ingo/Python Files/Course-project4/high-level-train-features.npz\") as npz_file:\n",
    "    hl_tr_features = npz_file[\"features\"]\n",
    "    tr_labels = npz_file[\"labels\"]\n",
    "    \n",
    "print(\"train features shape:\", hl_tr_features.shape)\n",
    "print(\"train labels shape:\", tr_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation features shape: (139, 1280)\n",
      "validation labels shape: (139,)\n"
     ]
    }
   ],
   "source": [
    "# validation set\n",
    "with np.load(\"/Users/Ingo/Python Files/Course-project4/high-level-valid-features.npz\") as npz_file:\n",
    "    hl_val_features = npz_file[\"features\"]\n",
    "    val_labels = npz_file[\"labels\"]\n",
    "    \n",
    "print(\"validation features shape:\", hl_val_features.shape)\n",
    "print(\"validation labels shape:\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test features shape: (50, 1280)\n",
      "test labels shape: (50, 1280)\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "with np.load(\"/Users/Ingo/Python Files/Course-project4/high-level-test-features.npz\") as npz_file:\n",
    "    hl_te_features = npz_file[\"features\"]\n",
    "    te_labels = npz_file[\"labels\"]\n",
    "    \n",
    "print(\"test features shape:\", hl_te_features.shape)\n",
    "print(\"test labels shape:\", hl_te_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bagging (Bootstrap AGGregatING) to fight overfitting problem of simple Decision Trees\n",
    "With bagging, we try to reduce the variance of an estimator by averaging the predictions from several instances of estimators trained on different samples of the data set. Random Forests are an example of bagging.\n",
    "\n",
    "Say we have 5 points in $X$ $x_1, x_2, x_3, x_4, x_5$. The idea is to generate different data sets by sampling $X$. These are called bootstrap samples because we sample with replacement. Hence, each new data set will likely contain duplicates.\n",
    "\n",
    "Example of 3 different sets:\n",
    "* $X_1 = x_1, x_2, x_3, x_4, x_5$\n",
    "* $X_2 = x_4, x_1, x_2, x_5, x_1$\n",
    "* $X_3 = x_2, x_4, x_3, x_2, x_5$\n",
    "\n",
    "One estimator will be fitted on each set. To compute predictions, we average the predictions of each estimator. \n",
    "\n",
    "In **random forests**, these estimators are decision trees. The advantage here is that the results are even more **decorrelated** because the decision tree will find different rules to structure the different subsets of samples.\n",
    "___\n",
    "\n",
    "I will start by building a random forest with `n_estimators = 5` with `max_depth = 11`. We saw with the simple decision trees that with depth = 11, we were at 100% accuracy for the train set while having a widely overfitted model. Let's see how having n = 5 estimators changes the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf1 train accuracy: 0.9857142857142858\n",
      "rf1 validation accuracy: 0.7841726618705036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create object with n = 5 estimators\n",
    "rf1 = RandomForestClassifier(n_estimators = 5, max_depth = 11, random_state = 0)\n",
    "\n",
    "# fit with train data\n",
    "rf1.fit(hl_tr_features, tr_labels)\n",
    "\n",
    "# get accuracy on validation data\n",
    "rf1_accuracy = rf1.score(hl_val_features, val_labels)\n",
    "print(\"rf1 train accuracy:\", rf1.score(hl_tr_features, tr_labels))\n",
    "print(\"rf1 validation accuracy:\", rf1_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the model is extremely overfitting with a train accuracy of 99.5% and a validation accuracy of only 78%.\n",
    "\n",
    "Let's increase the number of estimators to fight overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf2 train accuracy: 1.0\n",
      "rf2 validation accuracy: 0.8633093525179856\n"
     ]
    }
   ],
   "source": [
    "# create object with n = 100 estimators\n",
    "rf2 = RandomForestClassifier(n_estimators = 100, max_depth = 11, random_state = 0)\n",
    "\n",
    "# fit training data\n",
    "rf2.fit(hl_tr_features, tr_labels)\n",
    "\n",
    "# get accuracy on validation data\n",
    "print(\"rf2 train accuracy:\", rf2.score(hl_tr_features, tr_labels))\n",
    "print(\"rf2 validation accuracy:\", rf2.score(hl_val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy rose ca. 9 percentage points, but the model is still extremly overfitting with a validation accuracy of only 86%% in comparison to the 100% train accuracy. Let's remove the max_depth parameter and see what will happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf3 train accuracy: 1.0\n",
      "rf3 validation accuracy: 0.8633093525179856\n"
     ]
    }
   ],
   "source": [
    "# create object with n = 100 estimators and no depth limit\n",
    "rf3 = RandomForestClassifier(n_estimators = 100, max_depth = None, random_state = 0)\n",
    "\n",
    "# fit training data\n",
    "rf3.fit(hl_tr_features, tr_labels)\n",
    "\n",
    "# get accuracy on validation data\n",
    "print(\"rf3 train accuracy:\", rf3.score(hl_tr_features, tr_labels))\n",
    "print(\"rf3 validation accuracy:\", rf3.score(hl_val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that nothing is changing proves that we reached the maximum depth with `max_depth = 11`.\n",
    "\n",
    "Let's increase the number of estimators to 1000 and see whether we will see a significant increase in validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf4 train accuracy: 1.0\n",
      "rf4 validation accuracy: 0.8848920863309353\n"
     ]
    }
   ],
   "source": [
    "# create object with n = 1000\n",
    "rf4 = RandomForestClassifier(n_estimators = 1000, max_depth = None, random_state = 0)\n",
    "\n",
    "# fit training data\n",
    "rf4.fit(hl_tr_features, tr_labels)\n",
    "\n",
    "# get accuracy on validation data\n",
    "print(\"rf4 train accuracy:\", rf4.score(hl_tr_features, tr_labels))\n",
    "print(\"rf4 validation accuracy:\", rf4.score(hl_val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy with `n_estimators = 1000` rose 2 percentage points, so increasing the number of estimators seem to provide more accuracy, but at this stage only marginally. The model is still strongly overfitting.\n",
    "\n",
    "Because `rf4` still provided better results, we will use `rf4` with `n_estimators = 1000` on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf4 test validation: 0.96\n"
     ]
    }
   ],
   "source": [
    "rf4_accuracy = rf4.score(hl_te_features, te_labels)\n",
    "print(\"rf4 test validation:\", rf4_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do reach the 96% test accuracy and thus join the results ranges of k-NN and logistic regression, but our model is still strongly overfitting with train accuracy of 100%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "### Linear SVC Model\n",
    "As we can tune the `C` parameter , we will use the `GridSearchCV` approach. Therefore, train and validation set will be combined again and solely tested against the test set after grid search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined train features shape: (419, 1280)\n",
      "combined train labels shape: (419,)\n"
     ]
    }
   ],
   "source": [
    "# combine train and validation set\n",
    "train_features = np.append(hl_tr_features, hl_val_features, axis = 0)\n",
    "train_labels = np.append(tr_labels, val_labels, axis = 0)\n",
    "\n",
    "print(\"combined train features shape:\", train_features.shape)\n",
    "print(\"combined train labels shape:\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the grid\n",
    "grid = {\n",
    "    \"C\": np.logspace(-4, 4, num = 50), # test 50 C values from 0.0001 to 10,000\n",
    "}\n",
    "\n",
    "# create LinearSVC object\n",
    "linear_svc = LinearSVC()\n",
    "\n",
    "# create GridSearchCV object\n",
    "linear_svm_grid = GridSearchCV(estimator = linear_svc,\n",
    "                              param_grid = grid,\n",
    "                              n_jobs = -1, # use all available cores\n",
    "                              cv = 10,\n",
    "                              verbose = 1,\n",
    "                              return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   26.2s finished\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score', 'split7_test_score', 'split8_test_score', 'split9_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'split5_train_score', 'split6_train_score', 'split7_train_score', 'split8_train_score', 'split9_train_score', 'mean_train_score', 'std_train_score'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit linear_svm_grid\n",
    "linear_svm_grid.fit(train_features, train_labels)\n",
    "\n",
    "# see all available keys\n",
    "linear_svm_grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param C</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>std test</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>std train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000655129</td>\n",
       "      <td>0.906921</td>\n",
       "      <td>0.026940</td>\n",
       "      <td>0.974805</td>\n",
       "      <td>0.003633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000954095</td>\n",
       "      <td>0.904535</td>\n",
       "      <td>0.030004</td>\n",
       "      <td>0.985416</td>\n",
       "      <td>0.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0013895</td>\n",
       "      <td>0.904535</td>\n",
       "      <td>0.032181</td>\n",
       "      <td>0.992842</td>\n",
       "      <td>0.001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00294705</td>\n",
       "      <td>0.904535</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.995226</td>\n",
       "      <td>0.001063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00429193</td>\n",
       "      <td>0.904535</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.996288</td>\n",
       "      <td>0.001752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        param C  test accuracy  std test  train accuracy  std train\n",
       "5   0.000655129       0.906921  0.026940        0.974805   0.003633\n",
       "6   0.000954095       0.904535  0.030004        0.985416   0.003617\n",
       "7     0.0013895       0.904535  0.032181        0.992842   0.001688\n",
       "9    0.00294705       0.904535  0.028524        0.995226   0.001063\n",
       "10   0.00429193       0.904535  0.028524        0.996288   0.001752"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get results\n",
    "linear_svm_results = pd.DataFrame({\n",
    "    \"param C\": linear_svm_grid.cv_results_[\"param_C\"],\n",
    "    \"test accuracy\": linear_svm_grid.cv_results_[\"mean_test_score\"],\n",
    "    \"std test\": linear_svm_grid.cv_results_[\"std_test_score\"],\n",
    "    \"train accuracy\": linear_svm_grid.cv_results_[\"mean_train_score\"],\n",
    "    \"std train\": linear_svm_grid.cv_results_[\"std_train_score\"]\n",
    "})\n",
    "\n",
    "# sort df\n",
    "linear_svm_results.sort_values(by = \"test accuracy\", ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these values we can observe that we can reach accuracy values in the ranges of around 90%, but the model is again overfitting strongly with train accuracies between 97% and 100%. During these ranges, `C` is close to 0, which effectively means that there is already strong regulation on the model. \n",
    "\n",
    "Let's see the graph and check whether we can find a middle ground, similar to the experience with `C` in the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "plt.semilogx(linear_svm_results[\"param C\"], linear_svm_results[\"test accuracy\"], label = \"test set\")\n",
    "plt.semilogx(linear_svm_results[\"param C\"], linear_svm_results[\"train accuracy\"], label = \"train set\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"C regularization\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, based on the graph again, I will pick `C = 10^(-3.5)`, fit the model, and calculate train and test accuracy to see whether we can reach similar results but with less overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9451073985680191\n",
      "test accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# create object\n",
    "linear_svc2 = LinearSVC(C = 10**(-3.5), random_state = 0)\n",
    "\n",
    "# fit object\n",
    "linear_svc2.fit(train_features, train_labels)\n",
    "\n",
    "# get accuracy of both train and test set\n",
    "print(\"train accuracy:\", linear_svc2.score(train_features, train_labels))\n",
    "linear_svc2_accuracy = linear_svc2.score(hl_te_features, te_labels)\n",
    "print(\"test accuracy:\", linear_svc2_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we were able to find a regularization strength which prevents overfitting but allows enough learning ability to get a better generalization on the test set than on the training set itself. \n",
    "\n",
    "Furthermore, the linear model already provides us with results in the ranges of logistic regression, decision trees and random forests, but not quite better results than the 98% of k-NN.\n",
    "\n",
    "Let's now try the `rbf` kernel of `SVC`\n",
    "___\n",
    "### RBF kernel\n",
    "Here, we can tune both `C` and `gamma`, so we will again run grid-search cross-validation to check which combination works best.\n",
    "\n",
    "$\\gamma$ controls the influence each data point has. We can think of $\\gamma$ as a way to control the smoothness of the decision borders, i.e. whether it is strongly impacted by sole data points or robost again certain points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# create object with rbf kernel\n",
    "rbf_svc = SVC(kernel = \"rbf\")\n",
    "\n",
    "# create a grid\n",
    "rbf_grid = {\n",
    "    \"C\": np.logspace(-4, 4, num = 50), # 50 C values between 0.0001 and 10,000\n",
    "    \"gamma\": np.logspace(-4, 3, num = 8) # 10 gamma values between 0.0001 and 1,000\n",
    "}\n",
    "\n",
    "# create grid search CV object\n",
    "rbf_svc_cv = GridSearchCV(rbf_svc, rbf_grid, cv = 10, verbose = 1, n_jobs = -1, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed: 12.5min finished\n",
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score', 'split7_test_score', 'split8_test_score', 'split9_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'split5_train_score', 'split6_train_score', 'split7_train_score', 'split8_train_score', 'split9_train_score', 'mean_train_score', 'std_train_score'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the GridSearchCV object\n",
    "rbf_svc_cv.fit(train_features, train_labels)\n",
    "\n",
    "# see keys in results\n",
    "rbf_svc_cv.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>test score</th>\n",
       "      <th>std test</th>\n",
       "      <th>train score</th>\n",
       "      <th>std train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.75751</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.923628</td>\n",
       "      <td>0.032646</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>11.514</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.921241</td>\n",
       "      <td>0.029360</td>\n",
       "      <td>0.982498</td>\n",
       "      <td>0.002958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2.55955</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.918854</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>0.993107</td>\n",
       "      <td>0.001291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>5.42868</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.918854</td>\n",
       "      <td>0.035610</td>\n",
       "      <td>0.954396</td>\n",
       "      <td>0.004795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>16.7683</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.918854</td>\n",
       "      <td>0.034432</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     param_C param_gamma  test score  std test  train score  std train\n",
       "209  1.75751       0.001    0.923628  0.032646     0.990719   0.001779\n",
       "248   11.514      0.0001    0.921241  0.029360     0.982498   0.002958\n",
       "217  2.55955       0.001    0.918854  0.028488     0.993107   0.001291\n",
       "232  5.42868      0.0001    0.918854  0.035610     0.954396   0.004795\n",
       "256  16.7683      0.0001    0.918854  0.034432     0.990719   0.001779"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the results\n",
    "rbf_svc_results = pd.DataFrame({\n",
    "    \"param_C\": rbf_svc_cv.cv_results_[\"param_C\"],\n",
    "    \"param_gamma\": rbf_svc_cv.cv_results_[\"param_gamma\"],\n",
    "    \"test score\": rbf_svc_cv.cv_results_[\"mean_test_score\"],\n",
    "    \"std test\": rbf_svc_cv.cv_results_[\"std_test_score\"],\n",
    "    \"train score\": rbf_svc_cv.cv_results_[\"mean_train_score\"],\n",
    "    \"std train\": rbf_svc_cv.cv_results_[\"std_train_score\"]\n",
    "})\n",
    "\n",
    "rbf_svc_results.sort_values(by = \"test score\", ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check numerically where the difference between train and test score is minimal, and sort the DataFrame by that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>test score</th>\n",
       "      <th>std test</th>\n",
       "      <th>train score</th>\n",
       "      <th>std train</th>\n",
       "      <th>minimal diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.75751</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.923628</td>\n",
       "      <td>0.032646</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.067092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>11.514</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.921241</td>\n",
       "      <td>0.029360</td>\n",
       "      <td>0.982498</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.061257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>5.42868</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.918854</td>\n",
       "      <td>0.035610</td>\n",
       "      <td>0.954396</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.035542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>16.7683</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.918854</td>\n",
       "      <td>0.034432</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.071865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2.55955</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.918854</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>0.993107</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.074252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.20679</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.982231</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.065763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>3.72759</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.029543</td>\n",
       "      <td>0.994960</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.078492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>51.7947</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.995492</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.079024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.828643</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.914081</td>\n",
       "      <td>0.036421</td>\n",
       "      <td>0.964198</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.050116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>24.4205</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.914081</td>\n",
       "      <td>0.031088</td>\n",
       "      <td>0.992844</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.078762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>35.5648</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.914081</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.994960</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.080879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>5.42868</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.914081</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>0.995755</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.081674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>75.4312</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.914081</td>\n",
       "      <td>0.027538</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.085655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>3.72759</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.911695</td>\n",
       "      <td>0.032044</td>\n",
       "      <td>0.942197</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.030503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7.90604</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.911695</td>\n",
       "      <td>0.032949</td>\n",
       "      <td>0.967382</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.055688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7.90604</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.909308</td>\n",
       "      <td>0.030461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>109.854</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.909308</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>159.986</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.909308</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>232.995</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.909308</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>339.322</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.909308</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      param_C param_gamma  test score  std test  train score  std train  \\\n",
       "209   1.75751       0.001    0.923628  0.032646     0.990719   0.001779   \n",
       "248    11.514      0.0001    0.921241  0.029360     0.982498   0.002958   \n",
       "232   5.42868      0.0001    0.918854  0.035610     0.954396   0.004795   \n",
       "256   16.7683      0.0001    0.918854  0.034432     0.990719   0.001779   \n",
       "217   2.55955       0.001    0.918854  0.028488     0.993107   0.001291   \n",
       "201   1.20679       0.001    0.916468  0.030071     0.982231   0.004137   \n",
       "225   3.72759       0.001    0.916468  0.029543     0.994960   0.001434   \n",
       "280   51.7947      0.0001    0.916468  0.027711     0.995492   0.001215   \n",
       "193  0.828643       0.001    0.914081  0.036421     0.964198   0.004346   \n",
       "264   24.4205      0.0001    0.914081  0.031088     0.992844   0.001197   \n",
       "272   35.5648      0.0001    0.914081  0.034920     0.994960   0.001434   \n",
       "233   5.42868       0.001    0.914081  0.032635     0.995755   0.001757   \n",
       "288   75.4312      0.0001    0.914081  0.027538     0.999736   0.000792   \n",
       "224   3.72759      0.0001    0.911695  0.032044     0.942197   0.004152   \n",
       "240   7.90604      0.0001    0.911695  0.032949     0.967382   0.004298   \n",
       "241   7.90604       0.001    0.909308  0.030461     1.000000   0.000000   \n",
       "296   109.854      0.0001    0.909308  0.024501     1.000000   0.000000   \n",
       "304   159.986      0.0001    0.909308  0.024501     1.000000   0.000000   \n",
       "312   232.995      0.0001    0.909308  0.024501     1.000000   0.000000   \n",
       "320   339.322      0.0001    0.909308  0.024501     1.000000   0.000000   \n",
       "\n",
       "     minimal diff  \n",
       "209      0.067092  \n",
       "248      0.061257  \n",
       "232      0.035542  \n",
       "256      0.071865  \n",
       "217      0.074252  \n",
       "201      0.065763  \n",
       "225      0.078492  \n",
       "280      0.079024  \n",
       "193      0.050116  \n",
       "264      0.078762  \n",
       "272      0.080879  \n",
       "233      0.081674  \n",
       "288      0.085655  \n",
       "224      0.030503  \n",
       "240      0.055688  \n",
       "241      0.090692  \n",
       "296      0.090692  \n",
       "304      0.090692  \n",
       "312      0.090692  \n",
       "320      0.090692  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate difference between train and test score\n",
    "rbf_svc_results[\"minimal diff\"] = rbf_svc_results[\"train score\"] - rbf_svc_results[\"test score\"]\n",
    "\n",
    "# sort df with least difference at the top\n",
    "rbf_svc_results.sort_values(by = [\"test score\", \"minimal diff\"], ascending = [False, True])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the DataFrame indices 232 and 224 are combinations of `C` and `gamma` which allow for 91%-92% test accuracy while \"only\" having a train accuracy of around 95%.\n",
    "\n",
    "As I have controlled for 2 parameters in the cross validation, I can't effectively visualize the change of accuracies in a graph as there are 2 parameters changing at the same time.\n",
    "\n",
    "I will choose to fit a rbf-kernel model with `C = 5.42868` and `gamma = 0.0001`, which means that `C` effectively doesn't regularize the model whereas gamma is very robust against outliers and forms \"hard\" borders on the decision surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy rbf kernel: 0.9570405727923628\n",
      "test accuracy rbf kernel: 0.96\n"
     ]
    }
   ],
   "source": [
    "# create object\n",
    "rbf_svc2 = SVC(C = 5.42868, gamma = 0.0001, kernel = \"rbf\")\n",
    "\n",
    "# fit object\n",
    "rbf_svc2.fit(train_features, train_labels)\n",
    "\n",
    "# get score on test data\n",
    "print(\"train accuracy rbf kernel:\", rbf_svc2.score(train_features, train_labels))\n",
    "rbf_svc2_accuracy = rbf_svc2.score(hl_te_features, te_labels)\n",
    "print(\"test accuracy rbf kernel:\", rbf_svc2_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a model that doesn't overfit and still reaches the common top 96% accuracy which other models have achieved, too. Until now, only k-NN was able to break the 96% accuracy with an 98% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame to store our the test accuracies and save the file\n",
    "save_df = pd.DataFrame({\n",
    "    \"model\": [\"random forest\", \"svm linear\", \"svm rbf\"],\n",
    "    \"test_accuracy\": [rf4_accuracy, linear_svc2_accuracy, rbf_svc2_accuracy]\n",
    "})\n",
    "\n",
    "# save the df\n",
    "save_df.to_csv(\"/Users/Ingo/Python Files/Course-project4/05_random-forest-svm-results.csv\",\n",
    "              index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
