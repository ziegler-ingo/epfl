{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr shape: (115027, 223)\n",
      "y_tr shape: (115027,)\n",
      "X_val shape: (41424, 223)\n",
      "y_val shape: (41424,)\n",
      "X_te shape: (41378, 223)\n",
      "y_te shape: (41378,)\n"
     ]
    }
   ],
   "source": [
    "# load combined train set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/train_set_preprocessed.npz\") as npz_file:\n",
    "    X_tr_np = npz_file[\"features\"]\n",
    "    y_tr = npz_file[\"labels\"]\n",
    "    print(\"X_tr shape:\", X_tr_np.shape)\n",
    "    print(\"y_tr shape:\", y_tr.shape)\n",
    "    \n",
    "# load combined val set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/val_set_preprocessed.npz\") as npz_file:\n",
    "    X_val_np = npz_file[\"features\"]\n",
    "    y_val = npz_file[\"labels\"]\n",
    "    print(\"X_val shape:\", X_val_np.shape)\n",
    "    print(\"y_val shape:\", y_val.shape)\n",
    "    \n",
    "# load combined test set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/test_set_preprocessed.npz\") as npz_file:\n",
    "    X_te_np = npz_file[\"features\"]\n",
    "    y_te = npz_file[\"labels\"]\n",
    "    print(\"X_te shape:\", X_te_np.shape)\n",
    "    print(\"y_te shape:\", y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr_b shape: (44295, 125)\n",
      "y_tr_b shape: (44295,)\n",
      "X_val_b shape: (15387, 125)\n",
      "y_val_b shape: (15387,)\n",
      "X_te_b shape: (15871, 125)\n",
      "y_te_b shape: (15871,)\n"
     ]
    }
   ],
   "source": [
    "# load B term train set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/train_set_preprocessed_b.npz\") as npz_file:\n",
    "    X_tr_b_np = npz_file[\"features\"]\n",
    "    y_tr_b = npz_file[\"labels\"]\n",
    "    print(\"X_tr_b shape:\", X_tr_b_np.shape)\n",
    "    print(\"y_tr_b shape:\", y_tr_b.shape)\n",
    "    \n",
    "# load B term val set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/val_set_preprocessed_b.npz\") as npz_file:\n",
    "    X_val_b_np = npz_file[\"features\"]\n",
    "    y_val_b = npz_file[\"labels\"]\n",
    "    print(\"X_val_b shape:\", X_val_b_np.shape)\n",
    "    print(\"y_val_b shape:\", y_val_b.shape)\n",
    "    \n",
    "# load B term test set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/test_set_preprocessed_b.npz\") as npz_file:\n",
    "    X_te_b_np = npz_file[\"features\"]\n",
    "    y_te_b = npz_file[\"labels\"]\n",
    "    print(\"X_te_b shape:\", X_te_b_np.shape)\n",
    "    print(\"y_te_b shape:\", y_te_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr_j shape: (62447, 137)\n",
      "y_tr_j shape: (62447,)\n",
      "X_val_j shape: (22864, 137)\n",
      "y_val_j shape: (22864,)\n",
      "X_te_j shape: (22738, 137)\n",
      "y_te_j shape: (22738,)\n"
     ]
    }
   ],
   "source": [
    "# load J term train set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/train_set_preprocessed_j.npz\") as npz_file:\n",
    "    X_tr_j_np = npz_file[\"features\"]\n",
    "    y_tr_j = npz_file[\"labels\"]\n",
    "    print(\"X_tr_j shape:\", X_tr_j_np.shape)\n",
    "    print(\"y_tr_j shape:\", y_tr_j.shape)\n",
    "    \n",
    "# load J term val set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/val_set_preprocessed_j.npz\") as npz_file:\n",
    "    X_val_j_np = npz_file[\"features\"]\n",
    "    y_val_j = npz_file[\"labels\"]\n",
    "    print(\"X_val_j shape:\", X_val_j_np.shape)\n",
    "    print(\"y_val_j shape:\", y_val_j.shape)\n",
    "    \n",
    "# load J term test set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/test_set_preprocessed_j.npz\") as npz_file:\n",
    "    X_te_j_np = npz_file[\"features\"]\n",
    "    y_te_j = npz_file[\"labels\"]\n",
    "    print(\"X_te_j shape:\", X_te_j_np.shape)\n",
    "    print(\"y_te_j shape:\", y_te_j.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all the files are very large, the computation time required for e.g. grid search gets extremely long. Therefore, I will use sparse matrices, which significantly speed up the compute time of every model and tuning operation.\n",
    "\n",
    "Scipy advises that it is better to construct matrices from numpy arrays using `lil_matrix` first, which is a linked-list matrix. Only after that it is advised to convert the matrix to sklearn's required `csr` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all matrices to sparse format to use in models\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "X_tr = lil_matrix(X_tr_np, dtype = np.float32).tocsr()\n",
    "X_val = lil_matrix(X_val_np, dtype = np.float32).tocsr()\n",
    "X_te = lil_matrix(X_te_np, dtype = np.float32).tocsr()\n",
    "\n",
    "X_tr_b = lil_matrix(X_tr_b_np, dtype = np.float32).tocsr()\n",
    "X_val_b = lil_matrix(X_val_b_np, dtype = np.float32).tocsr()\n",
    "X_te_b = lil_matrix(X_te_b_np, dtype = np.float32).tocsr()\n",
    "\n",
    "X_tr_j = lil_matrix(X_tr_j_np, dtype = np.float32).tocsr()\n",
    "X_val_j = lil_matrix(X_val_j_np, dtype = np.float32).tocsr()\n",
    "X_te_j = lil_matrix(X_te_j_np, dtype = np.float32).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most-Frequent Baseline\n",
    "We will now get the most-frequent baseline of all of our sets. The theory is to create a na√Øve model that always predicts the most frequent value of the train set and always predicts that value in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined test set accuracy: 0.58\n",
      "B term test set accuracy: 0.59\n",
      "J term test set accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# create object\n",
    "dummy = DummyClassifier(strategy = \"most_frequent\")\n",
    "\n",
    "# fit object, combined set\n",
    "dummy.fit(None, y_tr)\n",
    "# get accuracy of combined test set\n",
    "logreg_baseline = dummy.score(None, y_te)\n",
    "print(\"combined test set accuracy: {:.2f}\".format(logreg_baseline))\n",
    "\n",
    "# fit objet, B term\n",
    "dummy.fit(None, y_tr_b)\n",
    "# get accuracy of B term test set\n",
    "logreg_baseline_b = dummy.score(None, y_te_b)\n",
    "print(\"B term test set accuracy: {:.2f}\".format(logreg_baseline_b))\n",
    "\n",
    "# fit object, J term\n",
    "dummy.fit(None, y_tr_j)\n",
    "# get accuracy of J term test set\n",
    "logreg_baseline_j = dummy.score(None, y_te_j)\n",
    "print(\"J term test set accuracy: {:.2f}\".format(logreg_baseline_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our unique student data got partially multiplied in the merging process, hence our final results also got multiplied. As a consequence, the most common label `Pass` got multiplied, too, because all students who passed wrote multiple assessments which all have the final result `Pass`.\n",
    "\n",
    "A baseline accuracy of 58% or 59% is rather high, however, it is plausible as the label `Pass` got multiplied and now apparently accounts for around 60% of all labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "We will now build a logistic regression classifier. At first, we will check whether One-vs-Rest multi-class or softmax produces better results.\n",
    "\n",
    "#### Regarding scaling:\n",
    "One one hand, we need a sparse matrix because otherwise computation time is extremely high for the following estimators. On the other hand, `StandardScaler` doesn't accept a sparse matrix as input because [centering a sparse matrix would destroy the sparse structure](https://scikit-learn.org/stable/modules/preprocessing.html#scaling-sparse-data). Sklearn mentions that one way to fight this problem is to use `StandardScaler` and use `with_mean = False`. However, the suggested and preferred (by sklearn) way is to use [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler), which doesn't center the data around 0 but scales it in a `[-1, 1]` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvR/liblinear logistic regression accuracy, combined model: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# OvR, saga for large data sets\n",
    "logreg_ovr = LogisticRegression(multi_class = \"ovr\", solver = \"liblinear\")\n",
    "\n",
    "# create pipelines to apply MaxAbsScaler\n",
    "pipe_ovr = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()), # scale numerical features but don't center them to keep sparse matrix\n",
    "    (\"logreg_ovr\", logreg_ovr)]) # logistic regression object\n",
    "\n",
    "# fit with training data\n",
    "pipe_ovr.fit(X_tr, y_tr)\n",
    "\n",
    "# get accuracy on test data\n",
    "pipe_ovr_acc = pipe_ovr.score(X_te, y_te)\n",
    "\n",
    "print(\"OvR/liblinear logistic regression accuracy, combined model: {:.2f}\".format(pipe_ovr_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax/lbfgs logistic regression accuracy, combined model: 0.65\n"
     ]
    }
   ],
   "source": [
    "# liblinear isn't compatible with multinomial \n",
    "np.random.seed(0)\n",
    "\n",
    "# create object\n",
    "logreg_sm = LogisticRegression(multi_class = \"multinomial\", solver = \"lbfgs\", n_jobs = -1)\n",
    "\n",
    "# create pipeline\n",
    "pipe_sm = Pipeline([(\"scaler\", MaxAbsScaler()), (\"logreg_sm\", logreg_sm)])\n",
    "\n",
    "# fit with training data\n",
    "pipe_sm.fit(X_tr, y_tr)\n",
    "\n",
    "# get accuracy\n",
    "pipe_sm_acc = pipe_sm.score(X_te, y_te)\n",
    "print(\"Softmax/lbfgs logistic regression accuracy, combined model: {:.2f}\".format(pipe_sm_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax/sag logistic regression accuracy, combined model: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# create object\n",
    "logreg_sm2 = LogisticRegression(multi_class = \"multinomial\", solver = \"sag\", n_jobs = -1, max_iter = 200)\n",
    "\n",
    "# create pipeline\n",
    "pipe_sm2 = Pipeline([(\"scaler\", MaxAbsScaler()), (\"logreg_sm2\", logreg_sm2)])\n",
    "\n",
    "# fit with training data\n",
    "pipe_sm2.fit(X_tr, y_tr)\n",
    "\n",
    "# get accuracy\n",
    "pipe_sm2_acc = pipe_sm2.score(X_te, y_te)\n",
    "print(\"Softmax/sag logistic regression accuracy, combined model: {:.2f}\".format(pipe_sm2_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax/saga logistic regression accuracy, combined model: 0.66\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# create object\n",
    "logreg_sm3 = LogisticRegression(multi_class = \"multinomial\", solver = \"saga\", n_jobs = -1)\n",
    "\n",
    "# create pipeline\n",
    "pipe_sm3 = Pipeline([(\"scaler\", MaxAbsScaler()), (\"logreg_sm3\", logreg_sm3)])\n",
    "\n",
    "# fit with training data\n",
    "pipe_sm3.fit(X_tr, y_tr)\n",
    "\n",
    "# get accuracy\n",
    "pipe_sm3_acc = pipe_sm3.score(X_te, y_te)\n",
    "print(\"Softmax/saga logistic regression accuracy, combined model: {:.2f}\".format(pipe_sm3_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get marginally better results with `multi_class = \"multinomial\"` in combination with `solver = \"sag\"` or `solver = \"saga\"` than with `scaler = \"lbfgs\"` or `scaler = \"liblinear\"`. For `solver = \"sag\"`, we need 200 maximum iterations whereas `solver = \"saga\"` works with the default 100.\n",
    "For this reason, going forward, I will use `multi_class = \"multinomial\", solver = \"saga\"`.\n",
    "\n",
    "We will now start the process of finding the best regularization strength `C` for each of the combined/B/J sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of logistic regression grid: 20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# create 3 pipelines for our models\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"logreg\", LogisticRegression(multi_class = \"multinomial\", solver = \"saga\", n_jobs = -1, tol = 0.001,\n",
    "                                  max_iter = 300))]) # we still need more iterations for grid search\n",
    "\n",
    "\n",
    "# create grid, here, we only have one parameter: C\n",
    "grid_lr = ParameterGrid({\n",
    "    \"logreg__C\": np.logspace(-4, 1, 20) # hyperparameter affect model on logarithmic scale\n",
    "})\n",
    "\n",
    "# length of grid: 20 values\n",
    "print(\"length of logistic regression grid:\", len(grid_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg__C</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.976351</td>\n",
       "      <td>0.667895</td>\n",
       "      <td>0.648127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.647934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.455595</td>\n",
       "      <td>0.668374</td>\n",
       "      <td>0.647789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.623777</td>\n",
       "      <td>0.666791</td>\n",
       "      <td>0.647378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.483293</td>\n",
       "      <td>0.662810</td>\n",
       "      <td>0.646606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logreg__C  train_acc   val_acc\n",
       "17   2.976351   0.667895  0.648127\n",
       "19  10.000000   0.668817  0.647934\n",
       "18   5.455595   0.668374  0.647789\n",
       "16   1.623777   0.666791  0.647378\n",
       "14   0.483293   0.662810  0.646606"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined model\n",
    "# loop through all combinations\n",
    "np.random.seed(0)\n",
    "\n",
    "# save results\n",
    "logreg_results = []\n",
    "\n",
    "for param_C in grid_lr:\n",
    "    pipe_lr.set_params(**param_C)\n",
    "    \n",
    "    # fit pipe\n",
    "    pipe_lr.fit(X_tr, y_tr)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    test_acc = pipe_lr.score(X_val, y_val)\n",
    "    train_acc = pipe_lr.score(X_tr, y_tr)\n",
    "    \n",
    "    # append accuracy to param_C\n",
    "    param_C[\"val_acc\"] = test_acc\n",
    "    param_C[\"train_acc\"] = train_acc\n",
    "    \n",
    "    # append param_C to logreg_results\n",
    "    logreg_results.append(param_C)\n",
    "    \n",
    "# transform list to DataFrame\n",
    "logreg_results = pd.DataFrame(logreg_results)\n",
    "logreg_results.sort_values(by = \"val_acc\", ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results\n",
    "plt.plot(logreg_results[\"logreg__C\"], logreg_results[\"val_acc\"], label = \"val_acc\")\n",
    "plt.plot(logreg_results[\"logreg__C\"], logreg_results[\"train_acc\"], label = \"train_acc\")\n",
    "plt.xlabel(\"Regularization Strength (C)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"C-Regularization and Accuracy of Combined Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C` works inversely, meaning that smaller values indicate stronger regularization. In our case, values close to zero, produce the best results with very little overfitting. Let's get a closer look at which `C` the difference between train and validation set is smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg__C</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.078476</td>\n",
       "      <td>0.654073</td>\n",
       "      <td>0.641705</td>\n",
       "      <td>0.012367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.042813</td>\n",
       "      <td>0.648283</td>\n",
       "      <td>0.635670</td>\n",
       "      <td>0.012612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.143845</td>\n",
       "      <td>0.657932</td>\n",
       "      <td>0.644868</td>\n",
       "      <td>0.013065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023357</td>\n",
       "      <td>0.639919</td>\n",
       "      <td>0.625966</td>\n",
       "      <td>0.013954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.263665</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.645182</td>\n",
       "      <td>0.014125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logreg__C  train_acc   val_acc      diff\n",
       "11   0.078476   0.654073  0.641705  0.012367\n",
       "10   0.042813   0.648283  0.635670  0.012612\n",
       "12   0.143845   0.657932  0.644868  0.013065\n",
       "9    0.023357   0.639919  0.625966  0.013954\n",
       "13   0.263665   0.659306  0.645182  0.014125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_results[\"diff\"] = logreg_results[\"train_acc\"] - logreg_results[\"val_acc\"]\n",
    "logreg_results.sort_values(by = \"diff\", ascending = True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the least overfitting takes place at `C = 0.078476`. As we can see in the graph, from there onwards train accuracy gets only slightly better while overfitting grows.\n",
    "\n",
    "Our model thus far has a validation accuracy of 64.24%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg__C</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.670459</td>\n",
       "      <td>0.658803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.455595</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.657763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.976351</td>\n",
       "      <td>0.667841</td>\n",
       "      <td>0.656983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.623777</td>\n",
       "      <td>0.664815</td>\n",
       "      <td>0.656853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.885867</td>\n",
       "      <td>0.661474</td>\n",
       "      <td>0.655423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logreg__C  train_acc   val_acc\n",
       "19  10.000000   0.670459  0.658803\n",
       "18   5.455595   0.669534  0.657763\n",
       "17   2.976351   0.667841  0.656983\n",
       "16   1.623777   0.664815  0.656853\n",
       "15   0.885867   0.661474  0.655423"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B term\n",
    "# loop through all combinations\n",
    "np.random.seed(0)\n",
    "\n",
    "# save results\n",
    "logreg_results_b = []\n",
    "\n",
    "for param_C in grid_lr:\n",
    "    pipe_lr.set_params(**param_C)\n",
    "    \n",
    "    # fit pipe\n",
    "    pipe_lr.fit(X_tr_b, y_tr_b)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    val_acc = pipe_lr.score(X_val_b, y_val_b)\n",
    "    train_acc = pipe_lr.score(X_tr_b, y_tr_b)\n",
    "    \n",
    "    # append accuracy to param_C\n",
    "    param_C[\"val_acc\"] = val_acc\n",
    "    param_C[\"train_acc\"] = train_acc\n",
    "    \n",
    "    # append param_C to logreg_results\n",
    "    logreg_results_b.append(param_C)\n",
    "    \n",
    "# transform list to DataFrame\n",
    "logreg_results_b = pd.DataFrame(logreg_results_b)\n",
    "logreg_results_b.sort_values(by = \"val_acc\", ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results\n",
    "plt.plot(logreg_results_b[\"logreg__C\"], logreg_results_b[\"val_acc\"], label = \"val_acc\")\n",
    "plt.plot(logreg_results_b[\"logreg__C\"], logreg_results_b[\"train_acc\"], label = \"train_acc\")\n",
    "plt.xlabel(\"Regularization Strength (C)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"C-Regularization and Accuracy of B-Term\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg__C</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.483293</td>\n",
       "      <td>0.655401</td>\n",
       "      <td>0.653279</td>\n",
       "      <td>0.002123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.885867</td>\n",
       "      <td>0.661474</td>\n",
       "      <td>0.655423</td>\n",
       "      <td>0.006051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.623777</td>\n",
       "      <td>0.664815</td>\n",
       "      <td>0.656853</td>\n",
       "      <td>0.007962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.976351</td>\n",
       "      <td>0.667841</td>\n",
       "      <td>0.656983</td>\n",
       "      <td>0.010857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.670459</td>\n",
       "      <td>0.658803</td>\n",
       "      <td>0.011657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.455595</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.657763</td>\n",
       "      <td>0.011771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logreg__C  train_acc   val_acc      diff\n",
       "14   0.483293   0.655401  0.653279  0.002123\n",
       "15   0.885867   0.661474  0.655423  0.006051\n",
       "16   1.623777   0.664815  0.656853  0.007962\n",
       "17   2.976351   0.667841  0.656983  0.010857\n",
       "19  10.000000   0.670459  0.658803  0.011657\n",
       "18   5.455595   0.669534  0.657763  0.011771"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_results_b[\"diff\"] = logreg_results_b[\"train_acc\"] - logreg_results_b[\"val_acc\"]\n",
    "logreg_results_b.sort_values(by = \"diff\", ascending = True)[14:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are some values for `C` where the validation accuracy is higher than train accuracy, I prefer to use `C = 0.483293` as it has a higher overall accuracy with 0.2% overfitting. Decreasing `C` more, i.e. larger `C` values, only further increase the spread between train and validation accuracy.\n",
    "\n",
    "The resulting validation accuracy for the B-term is: 65.32%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg__C</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.976351</td>\n",
       "      <td>0.693388</td>\n",
       "      <td>0.676697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.693804</td>\n",
       "      <td>0.676435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.455595</td>\n",
       "      <td>0.693836</td>\n",
       "      <td>0.676085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.623777</td>\n",
       "      <td>0.691594</td>\n",
       "      <td>0.676041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.885867</td>\n",
       "      <td>0.688952</td>\n",
       "      <td>0.673111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logreg__C  train_acc   val_acc\n",
       "17   2.976351   0.693388  0.676697\n",
       "19  10.000000   0.693804  0.676435\n",
       "18   5.455595   0.693836  0.676085\n",
       "16   1.623777   0.691594  0.676041\n",
       "15   0.885867   0.688952  0.673111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# J term\n",
    "# loop through all combinations\n",
    "np.random.seed(0)\n",
    "\n",
    "# save results\n",
    "logreg_results_j = []\n",
    "\n",
    "for param_C in grid_lr:\n",
    "    pipe_lr.set_params(**param_C)\n",
    "    \n",
    "    # fit pipe\n",
    "    pipe_lr.fit(X_tr_j, y_tr_j)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    val_acc = pipe_lr.score(X_val_j, y_val_j)\n",
    "    train_acc = pipe_lr.score(X_tr_j, y_tr_j)\n",
    "    \n",
    "    # append accuracy to param_C\n",
    "    param_C[\"val_acc\"] = val_acc\n",
    "    param_C[\"train_acc\"] = train_acc\n",
    "    \n",
    "    # append param_C to logreg_results\n",
    "    logreg_results_j.append(param_C)\n",
    "    \n",
    "# transform list to DataFrame\n",
    "logreg_results_j = pd.DataFrame(logreg_results_j)\n",
    "logreg_results_j.sort_values(by = \"val_acc\", ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results\n",
    "plt.plot(logreg_results_j[\"logreg__C\"], logreg_results_j[\"val_acc\"], label = \"val_acc\")\n",
    "plt.plot(logreg_results_j[\"logreg__C\"], logreg_results_j[\"train_acc\"], label = \"train_acc\")\n",
    "plt.xlabel(\"Regularization Strength (C)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"C-Regularization and Accuracy of J-Term\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg__C</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.042813</td>\n",
       "      <td>0.662049</td>\n",
       "      <td>0.652685</td>\n",
       "      <td>0.009364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.078476</td>\n",
       "      <td>0.669288</td>\n",
       "      <td>0.659202</td>\n",
       "      <td>0.010085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.263665</td>\n",
       "      <td>0.680465</td>\n",
       "      <td>0.670093</td>\n",
       "      <td>0.010372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.143845</td>\n",
       "      <td>0.676414</td>\n",
       "      <td>0.665763</td>\n",
       "      <td>0.010651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023357</td>\n",
       "      <td>0.652954</td>\n",
       "      <td>0.642101</td>\n",
       "      <td>0.010853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logreg__C  train_acc   val_acc      diff\n",
       "10   0.042813   0.662049  0.652685  0.009364\n",
       "11   0.078476   0.669288  0.659202  0.010085\n",
       "13   0.263665   0.680465  0.670093  0.010372\n",
       "12   0.143845   0.676414  0.665763  0.010651\n",
       "9    0.023357   0.652954  0.642101  0.010853"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_results_j[\"diff\"] = logreg_results_j[\"train_acc\"] - logreg_results_j[\"val_acc\"]\n",
    "logreg_results_j.sort_values(by = \"diff\", ascending = True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the j-term model, we can reach some higher train accuracies while also overfitting more. A `C = 0.263665` allows us to reach a validation accuracy of 67.00% with only 1% overfitting, which is the best trade-off in my opinion.\n",
    "\n",
    "We will now evaluate our scores on the actual test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined logistic regression accuracy: 0.6533\n",
      "B term logistic regression accuracy: 0.6655\n",
      "J term logistic regression accuracy: 0.6527\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# create 3 pipelines, evaluate on test data with results from grid search\n",
    "logreg = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"logreg\", LogisticRegression(C = 0.078476, multi_class = \"multinomial\", solver = \"saga\", tol = 0.001,\n",
    "                                 max_iter = 300, n_jobs = -1))])\n",
    "\n",
    "# combined model, fit training data\n",
    "logreg.fit(X_tr, y_tr)\n",
    "\n",
    "# get accuracy on test set\n",
    "logreg_acc = logreg.score(X_te, y_te)\n",
    "print(\"Combined logistic regression accuracy: {:.4f}\".format(logreg_acc))\n",
    "\n",
    "\n",
    "# B term\n",
    "logreg_b = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"logreg\", LogisticRegression(C = 0.483293, multi_class = \"multinomial\", solver = \"saga\", tol = 0.001,\n",
    "                                 max_iter = 300, n_jobs = -1))])\n",
    "\n",
    "# fit on training data\n",
    "logreg_b.fit(X_tr_b, y_tr_b)\n",
    "\n",
    "# get accuracy on test set\n",
    "logreg_acc_b = logreg_b.score(X_te_b, y_te_b)\n",
    "print(\"B term logistic regression accuracy: {:.4f}\".format(logreg_acc_b))\n",
    "\n",
    "\n",
    "# J term\n",
    "logreg_j = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"logreg\", LogisticRegression(C = 0.263665, multi_class = \"multinomial\", solver = \"saga\", tol = 0.001,\n",
    "                                 max_iter = 300, n_jobs = -1))])\n",
    "\n",
    "# fit on training data\n",
    "logreg_j.fit(X_tr_j, y_tr_j)\n",
    "\n",
    "# get accuracy on test set\n",
    "logreg_acc_j = logreg_j.score(X_te_j, y_te_j)\n",
    "print(\"J term logistic regression accuracy: {:.4f}\".format(logreg_acc_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final logistic regression results are:\n",
    "* Combined set:\n",
    "    * train: 65.44%, val: 64.24%, test: 65.33%\n",
    "* B term:\n",
    "    * train: 65.54%, val: 65.32%, test: 66.55%\n",
    "* J term:\n",
    "    * train: 68.05%, val: 67.01%, test: 65.27%\n",
    "\n",
    "In comparison to our grid search validation scores, both the combined and B-term test scores have improved, but still only marginally: The combined model as well as B-term accuracy increased roughly ~1 percentage point. Nevertheless, our until now best performing validation model, the J-term set, decreased almost 2 percentage point in the test set. This means that the generalization of the separate J-term model isn't as good as e.g. the combined set. Both models had an overfitting of around 1 percentage point, but the combined set, unlike the J-term set, still managed to generalize better on the test set.\n",
    "\n",
    "In general, we were able to beat all baselines consistently by around 6-7 percentage points, which is a solid increase considering that the baseline was already around 58-59% accuracy.\n",
    "\n",
    "### Predicting final outcomes based on artificial student profiles\n",
    "In the following, we will use our tuned, combined model to make predictions based on invented student profiles. I will first generate 3 profiles, show the probabilities for each class, and then change certain demographic backgrounds, scores or VLE activity to see how the probabilities for each class change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_AAA', 'x0_BBB', 'x0_CCC', 'x0_DDD', 'x0_EEE', 'x0_FFF', 'x1_B', 'x2_F', 'x3_East Anglian Region', 'x3_East Midlands Region', 'x3_Ireland', 'x3_London Region', 'x3_North Region', 'x3_North Western Region', 'x3_Scotland', 'x3_South East Region', 'x3_South Region', 'x3_South West Region', 'x3_Wales', 'x3_West Midlands Region', 'x4_0', 'x4_1', 'x5_N', 'x6_-150.0', 'x6_-50.0'] ['x8_0', 'x9_forumng', 'x9_homepage', 'x9_oucontent', 'x9_quiz', 'x9_resource', 'x9_subpage', 'x10_0', 'highest_education', 'age_band', 'date_submitted', 'score', 'module_presentation_length', 'total_sites_used', 'total_clicks', 'avg_working_dates', 'imd_band']\n"
     ]
    }
   ],
   "source": [
    "# load tr_data_df to see which assessment IDs are in which course\n",
    "tr_data_df = pd.read_csv(\"/Users/Ingo/Python Files/Capstone Project/data_dfs/tr_data_df.csv\")\n",
    "\n",
    "# load column_names_cleaned\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/column_names_cleaned.npz\") as npz_file:\n",
    "    column_names_cleaned = list(npz_file[\"features\"])\n",
    "\n",
    "# show some columns which are needed to build a profile\n",
    "# x7 is not displayed because those are just ~180 id_assessments\n",
    "print(column_names_cleaned[:25], column_names_cleaned[-17:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37527    34889\n",
       "Name: id_assessment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get assessment of module AAA, arbitrarily chosen\n",
    "tr_data_df.loc[tr_data_df[\"code_module\"] == \"AAA\", \"id_assessment\"][21:22] # 1759\n",
    "\n",
    "# get assessment of module BBB\n",
    "tr_data_df.loc[tr_data_df[\"code_module\"] == \"BBB\", \"id_assessment\"][160:161] # 15012\n",
    "\n",
    "# get assessment of module EEE\n",
    "tr_data_df.loc[tr_data_df[\"code_module\"] == \"CCC\", \"id_assessment\"][1198:1199] # 25335\n",
    "\n",
    "# get assessment of module FFF\n",
    "tr_data_df.loc[tr_data_df[\"code_module\"] == \"FFF\", \"id_assessment\"][3142:3143] # 34889"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first student will:\n",
    "* enroll in module `EEE`\n",
    "* in the `J` term\n",
    "* be female\n",
    "* come from London region\n",
    "* studied for 60 or below credits\n",
    "* no disability\n",
    "* `date_registration` before 150 days in advance of presentation start\n",
    "* sit `id_assessment = 25335`\n",
    "* score is not banked\n",
    "* will learn most often with `quiz`\n",
    "* is on his second attempt\n",
    "* `highest_education = 2` --> A-Level or Equivalent\n",
    "* be 35 or younger\n",
    "* `date_submitted = 56`\n",
    "* assessment `score` of 71\n",
    "* `module_presentation_length = 265`\n",
    "* `total_sites_used = 145`\n",
    "* `total_clicks = 402`\n",
    "* `avg_working_dates = 99`\n",
    "* `imd_band = 65`\n",
    "\n",
    "I will now initialize an array with all zeros and then fill the needed columns with `1` or the respective other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "student1 = np.zeros(shape = (1, len(column_names_cleaned)))\n",
    "\n",
    "# define OHE values and all other values in above described order\n",
    "characteristics1 = [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, np.log(30+56), np.log(30+71), np.log(30+265),\n",
    "                   np.log(30+145), np.log(30+402), np.log(30+99), 65]\n",
    "\n",
    "# outline the column names to change values\n",
    "columns1 = [\"x0_EEE\", \"x1_B\", \"x2_F\", \"x3_London Region\", \"x4_0\", \"x5_N\", \"x6_-150.0\", \"x7_25335\", \"x8_0\",\n",
    "           \"x9_quiz\", \"x10_0\", \"highest_education\", \"age_band\", \"date_submitted\", \"score\",\n",
    "           \"module_presentation_length\", \"total_sites_used\", \"total_clicks\", \"avg_working_dates\",\n",
    "            \"imd_band\"]\n",
    "\n",
    "# iterate through columns1 and find indices of that column in column_names_cleaned\n",
    "indices1 = [column_names_cleaned.index(col1) for col1 in columns1]\n",
    "\n",
    "# change respective value from 0 to the one outlined in characterstics1\n",
    "for idx, new_val in zip(indices1, characteristics1):\n",
    "    student1[:, idx] = new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0472074 , 0.35962341, 0.55333773, 0.03983145]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction based on student1 profile\n",
    "logreg.predict_proba(student1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that this student will most certainly `Pass` the course with a probability of 55%. The second highest probability of 36% points towards `Withdrawn`. For this profile, I think it makes sense that the algorithm guesses that the student will pass as we have a `score` of 71 and an `avg_working_dates` of 99, which is centered. However, we saw from EDA that `total_clicks` and `total_sites_used` should be much higher for a `Pass` score as the passing median for `total_sites_used` is 452 and for `total_clicks` is 1493. Both of our these characteristics are below the median of `Fail`, so it seems that `score` and all demographics point towards `Pass` and are valed highly here.\n",
    "\n",
    "Let's lower the `score` to 45 and `highest_education` to 0, which marks _No formal education_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00792255, 0.57331258, 0.37908503, 0.03967984]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student1_2 = student1.copy()\n",
    "student1_2[:, indices1[14]] = np.log(30 + 45) # score change\n",
    "\n",
    "student1_2[:, indices1[11]] = 0\n",
    "\n",
    "# make prediction\n",
    "logreg.predict_proba(student1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that just these two characteristics changes turned the categories completely around. We now have a 57% probability that the student withdraws, and just a 37% probability that the student passes. The `score` and `highest_education` changes were definitely impactful.\n",
    "\n",
    "What is interesting to me is that the student before had a 4% chance of `Fail`, which has now shrunk to 0.79%. In my personal estimates, that value should also have risen as from a human perspective it is not clear whether the student might withdraw or fail with both low scores and VLE activity levels. Following the three predictions, we will evaluate with confusion matrices in what directions the predictions went wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student2 Profile: Let's simulate an overall strong activity level with a low score\n",
    "* enroll in module `BBB`\n",
    "* in the `B` term\n",
    "* be female\n",
    "* come from East Anglian Region\n",
    "* studied for 60 or below credits\n",
    "* no disability\n",
    "* `date_registration` between 150 and 50 days in advance of presentation start\n",
    "* sit `id_assessment = 15012`\n",
    "* score is not banked\n",
    "* will learn most often with `homepage`\n",
    "* is on his first attempt\n",
    "* `highest_education = 3` --> Higher Eduction Qualification\n",
    "* be 35 or younger\n",
    "* `date_submitted = 112`\n",
    "* assessment `score` of 21\n",
    "* `module_presentation_length = 241`\n",
    "* `total_sites_used = 1609`\n",
    "* `total_clicks = 4412`\n",
    "* `avg_working_dates = 79`\n",
    "* `imd_band = 75`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "student2 = np.zeros(shape = (1, len(column_names_cleaned)))\n",
    "\n",
    "# define OHE values and all other values in above described order\n",
    "characteristics2 = [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 3, 0, np.log(30+112), np.log(30+21), np.log(30+241),\n",
    "                   np.log(30+1609), np.log(30+4412), np.log(30+79), 75]\n",
    "\n",
    "# outline the column names to change values\n",
    "columns2 = [\"x0_BBB\", \"x1_B\", \"x2_F\", \"x3_East Anglian Region\", \"x4_0\", \"x5_N\", \"x6_-50.0\", \"x7_15012\",\n",
    "            \"x8_0\", \"x9_homepage\", \"x10_0\", \"highest_education\", \"age_band\", \"date_submitted\", \"score\",\n",
    "           \"module_presentation_length\", \"total_sites_used\", \"total_clicks\", \"avg_working_dates\",\n",
    "            \"imd_band\"]\n",
    "\n",
    "# iterate through columns1 and find indices of that column in column_names_cleaned\n",
    "indices2 = [column_names_cleaned.index(col2) for col2 in columns2]\n",
    "\n",
    "# change respective value from 0 to the one outlined in characterstics1\n",
    "for idx, new_val in zip(indices2, characteristics2):\n",
    "    student2[:, idx] = new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28994308, 0.05383733, 0.64235039, 0.0138692 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction based on student1 profile\n",
    "logreg.predict_proba(student2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it becomes pretty clear that this student might indeed fail despite all the very positive activity simply because `score` is very low. Maybe the logistic regression classifier needs the very low `score` to be able to predict `Fail` at all. In this case, the student still has a 64% of `Pass` and a 29% `Fail` probability. \n",
    "\n",
    "Let's change the module to `FFF` together with the assessment and then re-evaluate how a module change - leaving everything else equal - affects the final result probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08036455, 0.17038464, 0.71183874, 0.03741207]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building new student profile is easier than adjusting indices in the existing\n",
    "student2_2 = np.zeros(shape = (1, len(column_names_cleaned)))\n",
    "\n",
    "columns2_2 = [\"x0_FFF\", \"x1_B\", \"x2_F\", \"x3_East Anglian Region\", \"x4_0\", \"x5_N\", \"x6_-50.0\", \"x7_34889\",\n",
    "            \"x8_0\", \"x9_homepage\", \"x10_0\", \"highest_education\", \"age_band\", \"date_submitted\", \"score\",\n",
    "           \"module_presentation_length\", \"total_sites_used\", \"total_clicks\", \"avg_working_dates\",\n",
    "            \"imd_band\"]\n",
    "\n",
    "# iterate through columns1 and find indices of that column in column_names_cleaned\n",
    "indices2_2 = [column_names_cleaned.index(col2_2) for col2_2 in columns2_2]\n",
    "\n",
    "# change respective value from 0 to the one outlined in characterstics1\n",
    "for idx, new_val in zip(indices2_2, characteristics2): # characteristics2 stays the same\n",
    "    student2_2[:, idx] = new_val\n",
    "    \n",
    "# make new predictions\n",
    "logreg.predict_proba(student2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having only changed the module and the respective assessment id, the probability for `Fail` dropped from 29% to only 8%. At the same time, the chance of `Withdrawn` has risen from only 5% to 17%. Nevertheless, the `Pass` probability has risen even more to 71%, so it seems that a score of only 25 doesn't hurt the chances of passing as much in this module than in module `AAA`. Even the chance of finishing with distinction has risen from 1.3% to 3.7%.\n",
    "\n",
    "Let's try to invent a profile that convincingly predicts `Distinction` because I suspect that the model has a very hard time distinguishing among `Pass` and `Distinction`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student3 Profile: Let's try to simulate a convincingly `Distinction`-finishing student\n",
    "* enroll in module `AAA`\n",
    "* in the `J` term\n",
    "* be male\n",
    "* come from North Region\n",
    "* studied for 60 or below credits\n",
    "* no disability\n",
    "* `date_registration` more than 150 days in advance of presentation start\n",
    "* sit `id_assessment = 1759`\n",
    "* score is not banked\n",
    "* will learn most often with `forumng`\n",
    "* is on his first attempt\n",
    "* `highest_education = 4` --> Post Graduate Qualification\n",
    "* be 55 or older\n",
    "* `date_submitted = 60`\n",
    "* assessment `score` of 99\n",
    "* `module_presentation_length = 270`\n",
    "* `total_sites_used = 4533`\n",
    "* `total_clicks = 12446`\n",
    "* `avg_working_dates = 110`\n",
    "* `imd_band = 95`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.82191664e-01, 6.71159788e-04, 2.12914639e-01, 4.22253686e-03]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student3 = np.zeros(shape = (1, len(column_names_cleaned)))\n",
    "\n",
    "# define OHE values and all other values in above described order\n",
    "characteristics3 = [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, np.log(30+60), np.log(30+99), np.log(30+270),\n",
    "                   np.log(30+4533), np.log(30+12446), np.log(30+110), 95]\n",
    "\n",
    "# outline the column names to change values\n",
    "columns3 = [\"x0_AAA\", \"x1_B\", \"x2_F\", \"x3_North Region\", \"x4_0\", \"x5_N\", \"x6_-150.0\", \"x7_1759\",\n",
    "            \"x8_0\", \"x9_forumng\", \"x10_0\", \"highest_education\", \"age_band\", \"date_submitted\", \"score\",\n",
    "           \"module_presentation_length\", \"total_sites_used\", \"total_clicks\", \"avg_working_dates\",\n",
    "            \"imd_band\"]\n",
    "\n",
    "# iterate through columns1 and find indices of that column in column_names_cleaned\n",
    "indices3 = [column_names_cleaned.index(col3) for col3 in columns3]\n",
    "\n",
    "# change respective value from 0 to the one outlined in characterstics1\n",
    "for idx, new_val in zip(indices3, characteristics3):\n",
    "    student3[:, idx] = new_val\n",
    "    \n",
    "# make prediction with probabilities\n",
    "logreg.predict_proba(student3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can definitely see that the model doesn't correctly recognize the features of students finishing with `Distinction` - or maybe even said more broadly: correctly classifying edge cases. We have entered almost all values that have the largest distribution of `Distinction` based on EDA results, such as `score` of 99, `total_sites_used = 4533`, `total_clicks = 12446`, using `forumng` as the most used resource, having a very centered `avg_working_dates`, the highest available `imd_band` of 95, and yet, the model shows that the student will `Fail` with 78% probability. \n",
    "\n",
    "In the cases of `student1` and `student2` above, lowering the `score` in comparison to very average activity levels increased the chance of `Fail` and `Withdrawn` - as expected by a human classifier and as trends in EDA suggested. However, now with almost perfect aseessment scores and orders of magnitute more activity in the VLE - again as EDA suggested - should put us at a very high chance of finishing with `Distinction`. However now, we suddenly have a 78% of `Fail` and a 21% chance of `Pass`, which is very contradictory to what we would expect. This is definitely a weak spot of the model.\n",
    "\n",
    "### In-depth model evaluation\n",
    "In the following steps, I will explore the model predictions and its failures more broadly. A confusion matrix should be able to tell whether the model is indeed very bad at predicting both edge cases and cases requiring nuance to classify correctly among classes other than `Pass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_AAA</th>\n",
       "      <th>x0_BBB</th>\n",
       "      <th>x0_CCC</th>\n",
       "      <th>x0_DDD</th>\n",
       "      <th>x0_EEE</th>\n",
       "      <th>x0_FFF</th>\n",
       "      <th>x1_B</th>\n",
       "      <th>x2_F</th>\n",
       "      <th>x3_East Anglian Region</th>\n",
       "      <th>x3_East Midlands Region</th>\n",
       "      <th>...</th>\n",
       "      <th>x10_0</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>age_band</th>\n",
       "      <th>date_submitted</th>\n",
       "      <th>score</th>\n",
       "      <th>module_presentation_length</th>\n",
       "      <th>total_sites_used</th>\n",
       "      <th>total_clicks</th>\n",
       "      <th>avg_working_dates</th>\n",
       "      <th>imd_band</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.595120</td>\n",
       "      <td>4.553877</td>\n",
       "      <td>5.700444</td>\n",
       "      <td>5.484797</td>\n",
       "      <td>6.975414</td>\n",
       "      <td>4.154356</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.850147</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>5.700444</td>\n",
       "      <td>7.264730</td>\n",
       "      <td>8.438799</td>\n",
       "      <td>4.923315</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.382027</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>5.700444</td>\n",
       "      <td>7.264730</td>\n",
       "      <td>8.438799</td>\n",
       "      <td>4.923315</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.718499</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>5.700444</td>\n",
       "      <td>7.264730</td>\n",
       "      <td>8.438799</td>\n",
       "      <td>4.923315</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>5.700444</td>\n",
       "      <td>5.948035</td>\n",
       "      <td>6.904751</td>\n",
       "      <td>4.850303</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x0_AAA  x0_BBB  x0_CCC  x0_DDD  x0_EEE  x0_FFF  x1_B  x2_F  \\\n",
       "269     0.0     0.0     1.0     0.0     0.0     0.0   0.0   1.0   \n",
       "279     0.0     0.0     1.0     0.0     0.0     0.0   0.0   1.0   \n",
       "280     0.0     0.0     1.0     0.0     0.0     0.0   0.0   1.0   \n",
       "281     0.0     0.0     1.0     0.0     0.0     0.0   0.0   1.0   \n",
       "286     0.0     0.0     1.0     0.0     0.0     0.0   0.0   0.0   \n",
       "\n",
       "     x3_East Anglian Region  x3_East Midlands Region  ...  x10_0  \\\n",
       "269                     0.0                      0.0  ...    1.0   \n",
       "279                     0.0                      0.0  ...    1.0   \n",
       "280                     0.0                      0.0  ...    1.0   \n",
       "281                     0.0                      0.0  ...    1.0   \n",
       "286                     0.0                      0.0  ...    0.0   \n",
       "\n",
       "     highest_education  age_band  date_submitted     score  \\\n",
       "269                2.0       1.0        4.595120  4.553877   \n",
       "279                1.0       1.0        3.850147  4.852030   \n",
       "280                1.0       1.0        4.382027  4.852030   \n",
       "281                1.0       1.0        4.718499  4.859812   \n",
       "286                3.0       1.0        4.127134  4.787492   \n",
       "\n",
       "     module_presentation_length  total_sites_used  total_clicks  \\\n",
       "269                    5.700444          5.484797      6.975414   \n",
       "279                    5.700444          7.264730      8.438799   \n",
       "280                    5.700444          7.264730      8.438799   \n",
       "281                    5.700444          7.264730      8.438799   \n",
       "286                    5.700444          5.948035      6.904751   \n",
       "\n",
       "     avg_working_dates  imd_band  \n",
       "269           4.154356      45.0  \n",
       "279           4.923315      25.0  \n",
       "280           4.923315      25.0  \n",
       "281           4.923315      25.0  \n",
       "286           4.850303      55.0  \n",
       "\n",
       "[5 rows x 223 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to find `Distinction` predictions to see on what input the model predicted `Distinction`\n",
    "logreg_preds = logreg.predict(X_te)\n",
    "\n",
    "# create X_te_df to see wrong predictions\n",
    "X_te_df = pd.DataFrame(data = X_te.toarray(), columns = column_names_cleaned)\n",
    "X_te_df.loc[logreg_preds == 3, :][45:50] # arbitrary slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13244295, 0.11914807, 0.26763916, 0.48076981]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's broadly mirror the values of student 269 here to get probabilities\n",
    "student4 = np.zeros(shape = (1, len(column_names_cleaned)))\n",
    "\n",
    "# define OHE values and all other values in above described order\n",
    "characteristics4 = [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 4.59, 4.55, 5.7, 5.48, 6.97, 4.15, 45]\n",
    "\n",
    "# outline the column names to change values\n",
    "columns4 = [\"x0_AAA\", \"x1_B\", \"x2_F\", \"x3_North Region\", \"x4_0\", \"x5_N\", \"x6_-150.0\", \"x7_1759\",\n",
    "            \"x8_0\", \"x9_forumng\", \"x10_0\", \"highest_education\", \"age_band\", \"date_submitted\", \"score\",\n",
    "           \"module_presentation_length\", \"total_sites_used\", \"total_clicks\", \"avg_working_dates\",\n",
    "            \"imd_band\"]\n",
    "\n",
    "# iterate through columns1 and find indices of that column in column_names_cleaned\n",
    "indices4 = [column_names_cleaned.index(col4) for col4 in columns4]\n",
    "\n",
    "# change respective value from 0 to the one outlined in characterstics1\n",
    "for idx, new_val in zip(indices4, characteristics4):\n",
    "    student4[:, idx] = new_val\n",
    "    \n",
    "# make prediction with probabilities\n",
    "logreg.predict_proba(student4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date submitted of student 4: 68.49443016194631\n",
      "score of student 4: 64.63240831492406\n",
      "presentation length of student 4: 7.0348982925518316e+19\n",
      "total sites used of student 4: 209.84670737425535\n",
      "total clicks of student 4: 1034.2227505380908\n",
      "avg working dates of student 4: 33.434000298123344\n",
      "y_te of this prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"date submitted of student 4:\", np.exp(4.59) - 30)\n",
    "print(\"score of student 4:\", np.exp(4.55) - 30)\n",
    "print(\"presentation length of student 4:\", np.exp(45.7) - 30)\n",
    "print(\"total sites used of student 4:\", np.exp(5.48) - 30)\n",
    "print(\"total clicks of student 4:\", np.exp(6.97) - 30)\n",
    "print(\"avg working dates of student 4:\", np.exp(4.15) - 30)\n",
    "print(\"y_te of this prediction:\", y_te[269])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is, indeed, a problem in classifying `Distinction` and `Withdrawn`. The student, whose characteristics and statistics look like a very average-to-good student, is classified as finishing with `Distinction` with 48% probability, whereas this student in reality withdrew. \n",
    "\n",
    "From a human perspective, I would have guessed that he finished in class 2 - `Pass`, as his score is average and activity below average. I certainly wouldn't have classified him as `Distinction`. \n",
    "\n",
    "Comparing this observation to our invented almost-perfect score and very high activity `student3` really doesn't make sense and shows that the model isn't able to generalize well even for very obvious cases. This probably stems from unclearly structured training data where it wasn't common that _only_ very active and high-score students were labeled with `Distinction`. As a consequence, the pattern of `Distinction`-labeled students gets diluted and further classifications get distorted.\n",
    "\n",
    "Let's see the overall patterns of where this estimator succeeded and failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: Fail</th>\n",
       "      <th>pred: Withdrawn</th>\n",
       "      <th>pred: Pass</th>\n",
       "      <th>pred: Distinction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: Fail</th>\n",
       "      <td>499</td>\n",
       "      <td>23</td>\n",
       "      <td>5246</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: Withdrawn</th>\n",
       "      <td>4</td>\n",
       "      <td>1641</td>\n",
       "      <td>4120</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: Pass</th>\n",
       "      <td>334</td>\n",
       "      <td>427</td>\n",
       "      <td>22942</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: Distinction</th>\n",
       "      <td>56</td>\n",
       "      <td>1173</td>\n",
       "      <td>1744</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred: Fail  pred: Withdrawn  pred: Pass  pred: Distinction\n",
       "true: Fail                499               23        5246                 81\n",
       "true: Withdrawn             4             1641        4120                716\n",
       "true: Pass                334              427       22942                422\n",
       "true: Distinction          56             1173        1744               1950"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg_matrix = confusion_matrix(y_true = y_te, y_pred = logreg_preds)\n",
    "\n",
    "# convert to DataFrame\n",
    "logreg_matrix_df = pd.DataFrame(data = logreg_matrix, columns = [\"pred: Fail\", \"pred: Withdrawn\",\n",
    "                                                                \"pred: Pass\", \"pred: Distinction\"],\n",
    "                               index = [\"true: Fail\", \"true: Withdrawn\", \"true: Pass\", \"true: Distinction\"])\n",
    "logreg_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this confusion matrix we can see that there is indeed only one class that gets constantly correctly predicted: `Pass`. In that case, we correctly predict ~23,000 out of ~24,000 cases. The next best predicted class is, to my surprise, `Distinction`, where a simple majority is correctly predicted. However, nearly as many cases get misclassified as `Pass`, which I can relate to due to my above examples of invented student profiles. Furthermore, around 20% of `true: Distinction` cases get classified as `Withdrawn`, which also surprises me. Our above observed case of _Student3_ (extremely good scores and activity levels to be classified as `Fail`) might be happening in around 56 cases, where the true class is `Distinction` but the predicted class is `Fail`. \n",
    "\n",
    "Initially, I would have guessed that `Withdrawn` would be most difficult to classify as students with all kinds of profiles could randomly withdraw. Based on EDA it seemed like `Withdrawn` and `Fail` were mostly moving in parallel but `Fail` on a lower overall level (speaking in terms of scores and activity levels). Now it seems like the higher level of `Withdrawn` and the large and encompassing `Pass` midfield could be benefiting `Withdrawn` predictions as there might be a lot of overlap among the lower portion of the `Pass` class and the higher portion of `Withdrawn`. \n",
    "\n",
    "Overall, the `Fail` class is classified the worst by our model. Around 90% of all predictions where the true class is `Fail` go towards `Pass`, so the model doesn't expect these values to be closer to `Withdrawn` - as I would expect - but rather to be closer to `Pass`, which is another weak point of our model. Interestingly enough, the model classifies true `Fail` examples the least into `Withdrawn`, it rather classifies them as finshing with `Distinction`. \n",
    "\n",
    "To observe and evaluate more metrics like recall and precision scores of our models, I will present and discuss sklearn's `classification_report` as it combines all of those metrics into one report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.09      0.15      5849\n",
      "           1       0.50      0.25      0.34      6481\n",
      "           2       0.67      0.95      0.79     24125\n",
      "           3       0.62      0.40      0.48      4923\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     41378\n",
      "   macro avg       0.59      0.42      0.44     41378\n",
      "weighted avg       0.62      0.65      0.59     41378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logreg_report = classification_report(y_true = y_te, y_pred = logreg_preds)\n",
    "print(logreg_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report shows the precision, recall, and F1-score, as well as the total count of each class (support). As we have 4 classes here, i.e. not a binary label, we have 4 instances of each metric provided.\n",
    "\n",
    "The precision score measures how many times we are actually correct when we predict the positive class, i.e. $\\frac{\\text{TP}}{\\text{TP + FP}}$\n",
    "\n",
    "The recall score measures how many time we are actually correct with our positive prediction when it is, in fact, positive: $\\frac{\\text{TP}}{\\text{TP + FN}}$\n",
    "\n",
    "The F1-score combines both the precision and recall score. In thise case, however, I prefer to look at the scores on its own, especially the recall score because it captures directly the observations of the confusion matrix: How many times we classified each class correctly. \n",
    "\n",
    "For instance, the recall score of class `0` shows that we predicted 499 times `Fail` when the true value was indeed `Fail`. The 9% follows from: $\\frac{499}{5849} = ~0.09$\n",
    "\n",
    "This process can be repeated for every class and can thus be seen as an extension for our evaluation above: The model classified `Pass` 95% correctly, `Distinction` in second place 40% correctly, then `Withdrawn` only in 25% of cases, and `Fail` the worst with only 9% correct predictions. \n",
    "\n",
    "#### Main problem of this model\n",
    "One of the main problems of this model is that 9% recall rate for class `0`, i.e. `Fail`. If we saw this estimator as a binary classification between the labels `Fail` and `Pass`, `Fail` would mark the positive class and `Pass` would constitute the negative class. In case of predicting student success, it is much more hurtful to predict that a student would pass when in fact he won't. This is a type 2 error where the actual label is positive (--> student fails), but we predict the negative label (--> student passes).\n",
    "\n",
    "In a good model, we should strive to reduce false negatives as it might convey a false sense of security to the student. In theory, the student could enter all his background and characteristics into this model, and it would classify him as true positive in 9% of all cases. In other words, the model only tells students in 9% of all cases - on average - whether they would indeed fail. \n",
    "\n",
    "I will now plot the receiver operating characteristics (ROC) curve that visualizes this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.010527</td>\n",
       "      <td>0.089588</td>\n",
       "      <td>0.463197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.010527</td>\n",
       "      <td>0.089930</td>\n",
       "      <td>0.463162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.089930</td>\n",
       "      <td>0.462562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.090272</td>\n",
       "      <td>0.462222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.090272</td>\n",
       "      <td>0.462190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.091469</td>\n",
       "      <td>0.461344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.010752</td>\n",
       "      <td>0.091469</td>\n",
       "      <td>0.461218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.010752</td>\n",
       "      <td>0.091640</td>\n",
       "      <td>0.461064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.091640</td>\n",
       "      <td>0.461053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.091982</td>\n",
       "      <td>0.461026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fpr       tpr  thresholds\n",
       "400  0.010527  0.089588    0.463197\n",
       "401  0.010527  0.089930    0.463162\n",
       "402  0.010695  0.089930    0.462562\n",
       "403  0.010695  0.090272    0.462222\n",
       "404  0.010724  0.090272    0.462190\n",
       "405  0.010724  0.091469    0.461344\n",
       "406  0.010752  0.091469    0.461218\n",
       "407  0.010752  0.091640    0.461064\n",
       "408  0.010780  0.091640    0.461053\n",
       "409  0.010780  0.091982    0.461026"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# get all probabilities into one variable\n",
    "logreg_probs = logreg.predict_proba(X_te)\n",
    "\n",
    "# roc_curve returns three arrays, false positivity rate, true positivity rate (recall) and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_true = y_te, y_score = logreg_probs[:, 0], # positive class = Fail / 0\n",
    "                                pos_label = 0) \n",
    "\n",
    "# create DataFrame out of the three arrays\n",
    "roc_df = pd.DataFrame({\n",
    "    \"fpr\": fpr,\n",
    "    \"tpr\": tpr,\n",
    "    \"thresholds\": thresholds\n",
    "})\n",
    "\n",
    "# display at which threshold the ~9% recall score is\n",
    "roc_df[400:410]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we can see here that the ~9% recall score is at a probability threshold of 46%. \n",
    "\n",
    "In general, each row here tells us how low the probability threshold needs to be to get the desired tpr/recall score. As we are faced with a multiclass problem, the probabilities aren't as clearly interpretable as in a binary setting. Furthermore, because I simply sliced the probabilities array out of the 4 classes, we can't see that, for instance, the binary 50% threshold default delivers our above observed 9% recall. Nonetheless, the problem I want to show describe is still observeable in the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC curve \n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positivity Rate\")\n",
    "plt.ylabel(\"True Positivity Rate\")\n",
    "plt.title(\"ROC-Curve of True-Fail and Predict-Pass Problem\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more the curve is in the top left corner, the better it is for our classification. This would correspond to a high recall rate while simultaneously having a low false positivity rate. This would also go hand-in-hand with having a low false negativity rate, which we initially wanted to visualize. The false negativity rate can be deduced from the TPR by calculating: $\\text{FNR} = 1 - \\text{TPR}$. Having a curve that is much stronger to the top left corner also reduces the FNR, i.e. our desired state.\n",
    "\n",
    "Let's see to what level we had to lower our threshold to receive at least 85% recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>0.398435</td>\n",
       "      <td>0.851599</td>\n",
       "      <td>0.125696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>0.398435</td>\n",
       "      <td>0.851770</td>\n",
       "      <td>0.125689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>0.399308</td>\n",
       "      <td>0.851770</td>\n",
       "      <td>0.125457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>0.399308</td>\n",
       "      <td>0.851941</td>\n",
       "      <td>0.125448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>0.399336</td>\n",
       "      <td>0.851941</td>\n",
       "      <td>0.125445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>0.399336</td>\n",
       "      <td>0.852111</td>\n",
       "      <td>0.125444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>0.399561</td>\n",
       "      <td>0.852111</td>\n",
       "      <td>0.125404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>0.399561</td>\n",
       "      <td>0.852282</td>\n",
       "      <td>0.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>0.399645</td>\n",
       "      <td>0.852282</td>\n",
       "      <td>0.125340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>0.399645</td>\n",
       "      <td>0.852795</td>\n",
       "      <td>0.125313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fpr       tpr  thresholds\n",
       "6700  0.398435  0.851599    0.125696\n",
       "6701  0.398435  0.851770    0.125689\n",
       "6702  0.399308  0.851770    0.125457\n",
       "6703  0.399308  0.851941    0.125448\n",
       "6704  0.399336  0.851941    0.125445\n",
       "6705  0.399336  0.852111    0.125444\n",
       "6706  0.399561  0.852111    0.125404\n",
       "6707  0.399561  0.852282    0.125400\n",
       "6708  0.399645  0.852282    0.125340\n",
       "6709  0.399645  0.852795    0.125313"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_df[6700:6710]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we would have to lower our probability threshold to around 12.5% to get 85% recall for the `Fail` class. \n",
    "\n",
    "It is important to keep in mind that this is just a theoretical example that simplisticly created a binary problem out of a multi-class classification. In multi-clas problems, the final prediction is constantly affected by all other probability values. Changing the threshold here to 12.5% for the `Fail` class and thus classifying everything as `0` as soon as the probability hit that threshold would negatively affect all other classifications, so this is not a viable change on its own. \n",
    "\n",
    "All in all, our current model is highly biased in favor of the `Pass` class. Excluding the `Distinction` class, the model always predicts `Pass` most often, which shows us that the model is not able to differentiate between classes and thus predicts `Pass` most often. Even for the `Distinction` class, the model predicts only 40% of cases correctly (recall = 40%). The second most predicted class is again `Pass`, so even there seems to be problem of a lot of noise involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame to store our the test accuracies and save the file\n",
    "save_df = pd.DataFrame({\n",
    "    \"model\": [\"baseline\", \"baseline_b\", \"baseline_j\", \"lr\", \"lr_b\", \"lr_j\"],\n",
    "    \"test_accuracy\": [logreg_baseline, logreg_baseline_b, logreg_baseline_j,\n",
    "                      logreg_acc, logreg_acc_b, logreg_acc_j]})\n",
    "\n",
    "# save the df\n",
    "save_df.to_csv(\"/Users/Ingo/Python Files/Capstone Project/results/03-logistic-regression-results.csv\",\n",
    "              index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recall scores in variables\n",
    "logreg_recall_0 = 0.09\n",
    "logreg_recall_1 = 0.25\n",
    "logreg_recall_2 = 0.95\n",
    "logreg_recall_3 = 0.4\n",
    "\n",
    "# create a DataFrame to store recall scores and save the file\n",
    "save_df_recall = pd.DataFrame({\n",
    "    \"classes\": [0, 1, 2, 3],\n",
    "    \"recall\": [logreg_recall_0, logreg_recall_1, logreg_recall_2, logreg_recall_3]})\n",
    "\n",
    "# save the df\n",
    "save_df_recall.to_csv(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/results/03-logistic-regression-recall-results.csv\",\n",
    "    index = False)\n",
    "\n",
    "# save roc_curve values in df\n",
    "roc_df.to_csv(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/results/03-logistic-regression-roc-results.csv\",\n",
    "    index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
