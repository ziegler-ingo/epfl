{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr shape: (115027, 223)\n",
      "y_tr shape: (115027,)\n",
      "X_val shape: (41424, 223)\n",
      "y_val shape: (41424,)\n",
      "X_te shape: (41378, 223)\n",
      "y_te shape: (41378,)\n"
     ]
    }
   ],
   "source": [
    "# load combined train set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/train_set_preprocessed.npz\") as npz_file:\n",
    "    X_tr_np = npz_file[\"features\"]\n",
    "    y_tr = npz_file[\"labels\"]\n",
    "    print(\"X_tr shape:\", X_tr_np.shape)\n",
    "    print(\"y_tr shape:\", y_tr.shape)\n",
    "    \n",
    "# load combined val set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/val_set_preprocessed.npz\") as npz_file:\n",
    "    X_val_np = npz_file[\"features\"]\n",
    "    y_val = npz_file[\"labels\"]\n",
    "    print(\"X_val shape:\", X_val_np.shape)\n",
    "    print(\"y_val shape:\", y_val.shape)\n",
    "    \n",
    "# load combined test set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/test_set_preprocessed.npz\") as npz_file:\n",
    "    X_te_np = npz_file[\"features\"]\n",
    "    y_te = npz_file[\"labels\"]\n",
    "    print(\"X_te shape:\", X_te_np.shape)\n",
    "    print(\"y_te shape:\", y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr_b shape: (44295, 125)\n",
      "y_tr_b shape: (44295,)\n",
      "X_val_b shape: (15387, 125)\n",
      "y_val_b shape: (15387,)\n",
      "X_te_b shape: (15871, 125)\n",
      "y_te_b shape: (15871,)\n"
     ]
    }
   ],
   "source": [
    "# load B term train set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/train_set_preprocessed_b.npz\") as npz_file:\n",
    "    X_tr_b_np = npz_file[\"features\"]\n",
    "    y_tr_b = npz_file[\"labels\"]\n",
    "    print(\"X_tr_b shape:\", X_tr_b_np.shape)\n",
    "    print(\"y_tr_b shape:\", y_tr_b.shape)\n",
    "    \n",
    "# load B term val set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/val_set_preprocessed_b.npz\") as npz_file:\n",
    "    X_val_b_np = npz_file[\"features\"]\n",
    "    y_val_b = npz_file[\"labels\"]\n",
    "    print(\"X_val_b shape:\", X_val_b_np.shape)\n",
    "    print(\"y_val_b shape:\", y_val_b.shape)\n",
    "    \n",
    "# load B term test set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/test_set_preprocessed_b.npz\") as npz_file:\n",
    "    X_te_b_np = npz_file[\"features\"]\n",
    "    y_te_b = npz_file[\"labels\"]\n",
    "    print(\"X_te_b shape:\", X_te_b_np.shape)\n",
    "    print(\"y_te_b shape:\", y_te_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr_j shape: (62447, 137)\n",
      "y_tr_j shape: (62447,)\n",
      "X_val_j shape: (22864, 137)\n",
      "y_val_j shape: (22864,)\n",
      "X_te_j shape: (22738, 137)\n",
      "y_te_j shape: (22738,)\n"
     ]
    }
   ],
   "source": [
    "# load J term train set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/train_set_preprocessed_j.npz\") as npz_file:\n",
    "    X_tr_j_np = npz_file[\"features\"]\n",
    "    y_tr_j = npz_file[\"labels\"]\n",
    "    print(\"X_tr_j shape:\", X_tr_j_np.shape)\n",
    "    print(\"y_tr_j shape:\", y_tr_j.shape)\n",
    "    \n",
    "# load J term val set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/val_set_preprocessed_j.npz\") as npz_file:\n",
    "    X_val_j_np = npz_file[\"features\"]\n",
    "    y_val_j = npz_file[\"labels\"]\n",
    "    print(\"X_val_j shape:\", X_val_j_np.shape)\n",
    "    print(\"y_val_j shape:\", y_val_j.shape)\n",
    "    \n",
    "# load J term test set\n",
    "with np.load(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/preprocessed_dfs/test_set_preprocessed_j.npz\") as npz_file:\n",
    "    X_te_j_np = npz_file[\"features\"]\n",
    "    y_te_j = npz_file[\"labels\"]\n",
    "    print(\"X_te_j shape:\", X_te_j_np.shape)\n",
    "    print(\"y_te_j shape:\", y_te_j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all matrices to sparse format to use in models\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "X_tr = lil_matrix(X_tr_np, dtype = np.float32).tocsr()\n",
    "X_val = lil_matrix(X_val_np, dtype = np.float32).tocsr()\n",
    "X_te = lil_matrix(X_te_np, dtype = np.float32).tocsr()\n",
    "\n",
    "X_tr_b = lil_matrix(X_tr_b_np, dtype = np.float32).tocsr()\n",
    "X_val_b = lil_matrix(X_val_b_np, dtype = np.float32).tocsr()\n",
    "X_te_b = lil_matrix(X_te_b_np, dtype = np.float32).tocsr()\n",
    "\n",
    "X_tr_j = lil_matrix(X_tr_j_np, dtype = np.float32).tocsr()\n",
    "X_val_j = lil_matrix(X_val_j_np, dtype = np.float32).tocsr()\n",
    "X_te_j = lil_matrix(X_te_j_np, dtype = np.float32).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "#### Using Bagging (Bootstrap AGGregatING) to fight overfitting problem of simple Decision Trees\n",
    "With bagging, we try to reduce the variance of an estimator by averaging the predictions from several instances of estimators trained on different samples of the data set. Random Forests are an example of bagging.\n",
    "\n",
    "Say we have 5 points in $X$ $x_1, x_2, x_3, x_4, x_5$. The idea is to generate different data sets by sampling $X$. These are called bootstrap samples because we sample with replacement. Hence, each new data set will likely contain duplicates.\n",
    "\n",
    "Example of 3 different sets:\n",
    "\n",
    "$X_1 = x_1, x_2, x_3, x_4, x_5$\n",
    "\n",
    "$X_2 = x_4, x_1, x_2, x_5, x_1$\n",
    "\n",
    "$X_3 = x_2, x_4, x_3, x_2, x_5$\n",
    "\n",
    "One estimator will be fitted on each set. To compute predictions, we average the predictions of each estimator.\n",
    "\n",
    "In random forests, these estimators are decision trees. The advantage here is that the results are even more decorrelated because the decision tree will find different rules to structure the different subsets of samples.\n",
    "___\n",
    "I will base my random forest models on the observed depth of the value which led simple decision trees to train accuracies of ~99%. For our earlier created models, a depth of `max_depth = 28` brought us to 98.8%.\n",
    "\n",
    "I will then use grid-search to find the optimal number of `n_estimators` to find a balance and reduce overfitting.\n",
    "\n",
    "At first, I will test 4 values for `n_estimators` in the combined set to get a broad overview of which range of `n_estimators` I need to specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# create pipeline\n",
    "rf_pipe_prelim = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"rf\", RandomForestClassifier(max_depth = 28, random_state = 0))\n",
    "])\n",
    "\n",
    "rf_grid1 = ParameterGrid({\n",
    "    \"rf__n_estimators\": [10, 50, 100, 200] # test these values at first\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.984856</td>\n",
       "      <td>0.649817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.984421</td>\n",
       "      <td>0.647620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.982265</td>\n",
       "      <td>0.645688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.971189</td>\n",
       "      <td>0.622369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf__n_estimators  train_acc   val_acc\n",
       "3               200   0.984856  0.649817\n",
       "2               100   0.984421  0.647620\n",
       "1                50   0.982265  0.645688\n",
       "0                10   0.971189  0.622369"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined model\n",
    "# loop through all combinations\n",
    "\n",
    "# save results\n",
    "rf_results1 = []\n",
    "\n",
    "for param_n_estimator in rf_grid1:\n",
    "    rf_pipe_prelim.set_params(**param_n_estimator)\n",
    "    \n",
    "    # fit pipe\n",
    "    rf_pipe_prelim.fit(X_tr, y_tr)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    val_acc = rf_pipe_prelim.score(X_val, y_val)\n",
    "    train_acc = rf_pipe_prelim.score(X_tr, y_tr)\n",
    "    \n",
    "    # append accuracy to param_max_depth\n",
    "    param_n_estimator[\"val_acc\"] = val_acc\n",
    "    param_n_estimator[\"train_acc\"] = train_acc\n",
    "    \n",
    "    # append param_max_depth to dt_results\n",
    "    rf_results1.append(param_n_estimator)\n",
    "    \n",
    "# transform list to DataFrame\n",
    "rf_results1 = pd.DataFrame(rf_results1)\n",
    "rf_results1.sort_values(by = \"val_acc\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing these results, I think that we can't beat the accuracy level of around ~65% independently of any model. The random forests overfit very strongly even at 50 estimators.\n",
    "\n",
    "As there is only a marginal difference in accuracy among 50, 100, and 200 estimators, I will instead, mainly for reasons of computational capacity, choose to fix the random forest classifier at `n_estimators = 50` and vary the depth now to find a model which doesn't overfit at 100% while the validation accuracy stays at ~64%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.848218</td>\n",
       "      <td>0.643999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0.800447</td>\n",
       "      <td>0.639243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.746729</td>\n",
       "      <td>0.635042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.696967</td>\n",
       "      <td>0.626473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.661853</td>\n",
       "      <td>0.620775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.626418</td>\n",
       "      <td>0.603611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.594373</td>\n",
       "      <td>0.572615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.588158</td>\n",
       "      <td>0.565904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.584393</td>\n",
       "      <td>0.562766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.584393</td>\n",
       "      <td>0.562766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf__max_depth  train_acc   val_acc\n",
       "9             19   0.848218  0.643999\n",
       "8             17   0.800447  0.639243\n",
       "7             15   0.746729  0.635042\n",
       "6             13   0.696967  0.626473\n",
       "5             11   0.661853  0.620775\n",
       "4              9   0.626418  0.603611\n",
       "3              7   0.594373  0.572615\n",
       "2              5   0.588158  0.565904\n",
       "0              1   0.584393  0.562766\n",
       "1              3   0.584393  0.562766"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined model\n",
    "\n",
    "# create second pipeline\n",
    "rf_pipe_prelim2 = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"rf\", RandomForestClassifier(n_estimators = 50, random_state = 0))\n",
    "])\n",
    "\n",
    "rf_grid2 = ParameterGrid({\n",
    "    \"rf__max_depth\": np.arange(1, 20, 2) # depth of 28 is already 100% train accuracy\n",
    "})\n",
    "\n",
    "# loop through all combinations\n",
    "\n",
    "# save results\n",
    "rf_results2 = []\n",
    "\n",
    "for param_max_depth in rf_grid2:\n",
    "    rf_pipe_prelim2.set_params(**param_max_depth)\n",
    "    \n",
    "    # fit pipe\n",
    "    rf_pipe_prelim2.fit(X_tr, y_tr)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    val_acc = rf_pipe_prelim2.score(X_val, y_val)\n",
    "    train_acc = rf_pipe_prelim2.score(X_tr, y_tr)\n",
    "    \n",
    "    # append accuracy to param_max_depth\n",
    "    param_max_depth[\"val_acc\"] = val_acc\n",
    "    param_max_depth[\"train_acc\"] = train_acc\n",
    "    \n",
    "    # append param_max_depth to dt_results\n",
    "    rf_results2.append(param_max_depth)\n",
    "    \n",
    "# transform list to DataFrame\n",
    "rf_results2 = pd.DataFrame(rf_results2)\n",
    "rf_results2.sort_values(by = \"val_acc\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results\n",
    "plt.plot(rf_results2[\"rf__max_depth\"], rf_results2[\"val_acc\"], label = \"val_acc\")\n",
    "plt.plot(rf_results2[\"rf__max_depth\"], rf_results2[\"train_acc\"], label = \"train_acc\")\n",
    "plt.xlabel(\"Maximum Depth of Tree\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Preliminary Maximum Depth and Accuracy of Combined Model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that every model is overfitting at least ~2 percentage points, starting already at `max_depth = 1`. The difference here is that we can observe a zone up to around `max_depth = 10` where both train and validation set accuracies rise but overfitting doesn't.\n",
    "\n",
    "Based on these findings, I will now create a `ParameterGrid` of a mix of the realistic ranges in order to find the optimal combination of `max_depth` and `n_estimators`. These combinations will then be tested on the combined, B-, and J-term sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.703939</td>\n",
       "      <td>0.630697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.699001</td>\n",
       "      <td>0.627221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>0.696967</td>\n",
       "      <td>0.626473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0.695767</td>\n",
       "      <td>0.625700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.693794</td>\n",
       "      <td>0.624638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.643884</td>\n",
       "      <td>0.614113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.640771</td>\n",
       "      <td>0.612833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.640919</td>\n",
       "      <td>0.611892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.636711</td>\n",
       "      <td>0.608681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.639015</td>\n",
       "      <td>0.608657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rf__max_depth  rf__n_estimators  train_acc   val_acc\n",
       "21             13                20   0.703939  0.630697\n",
       "20             13                10   0.699001  0.627221\n",
       "24             13                50   0.696967  0.626473\n",
       "23             13                40   0.695767  0.625700\n",
       "22             13                30   0.693794  0.624638\n",
       "16             10                20   0.643884  0.614113\n",
       "18             10                40   0.640771  0.612833\n",
       "19             10                50   0.640919  0.611892\n",
       "17             10                30   0.636711  0.608681\n",
       "15             10                10   0.639015  0.608657"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined model\n",
    "\n",
    "# create second pipeline\n",
    "rf_pipe = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"rf\", RandomForestClassifier(random_state = 0))\n",
    "])\n",
    "\n",
    "rf_grid = ParameterGrid({\n",
    "    \"rf__max_depth\": np.arange(1, 16, 3),\n",
    "    \"rf__n_estimators\": [10, 20, 30, 40, 50]\n",
    "})\n",
    "\n",
    "# loop through all combinations\n",
    "\n",
    "# save results\n",
    "rf_results = []\n",
    "\n",
    "for params in rf_grid:\n",
    "    rf_pipe.set_params(**params)\n",
    "    \n",
    "    # fit pipe\n",
    "    rf_pipe.fit(X_tr, y_tr)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    val_acc = rf_pipe.score(X_val, y_val)\n",
    "    train_acc = rf_pipe.score(X_tr, y_tr)\n",
    "    \n",
    "    # append accuracy to param_max_depth\n",
    "    params[\"val_acc\"] = val_acc\n",
    "    params[\"train_acc\"] = train_acc\n",
    "    \n",
    "    # append param_max_depth to dt_results\n",
    "    rf_results.append(params)\n",
    "    \n",
    "# transform list to DataFrame\n",
    "rf_results = pd.DataFrame(rf_results)\n",
    "rf_results.sort_values(by = \"val_acc\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.703939</td>\n",
       "      <td>0.630697</td>\n",
       "      <td>0.073242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.699001</td>\n",
       "      <td>0.627221</td>\n",
       "      <td>0.071780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>0.696967</td>\n",
       "      <td>0.626473</td>\n",
       "      <td>0.070494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0.695767</td>\n",
       "      <td>0.625700</td>\n",
       "      <td>0.070067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.693794</td>\n",
       "      <td>0.624638</td>\n",
       "      <td>0.069156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.643884</td>\n",
       "      <td>0.614113</td>\n",
       "      <td>0.029771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.640771</td>\n",
       "      <td>0.612833</td>\n",
       "      <td>0.027938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.640919</td>\n",
       "      <td>0.611892</td>\n",
       "      <td>0.029027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.636711</td>\n",
       "      <td>0.608681</td>\n",
       "      <td>0.028030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.639015</td>\n",
       "      <td>0.608657</td>\n",
       "      <td>0.030358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rf__max_depth  rf__n_estimators  train_acc   val_acc      diff\n",
       "21             13                20   0.703939  0.630697  0.073242\n",
       "20             13                10   0.699001  0.627221  0.071780\n",
       "24             13                50   0.696967  0.626473  0.070494\n",
       "23             13                40   0.695767  0.625700  0.070067\n",
       "22             13                30   0.693794  0.624638  0.069156\n",
       "16             10                20   0.643884  0.614113  0.029771\n",
       "18             10                40   0.640771  0.612833  0.027938\n",
       "19             10                50   0.640919  0.611892  0.029027\n",
       "17             10                30   0.636711  0.608681  0.028030\n",
       "15             10                10   0.639015  0.608657  0.030358"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results[\"diff\"] = rf_results[\"train_acc\"] - rf_results[\"val_acc\"]\n",
    "rf_results.sort_values(by = \"val_acc\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that `max_depth` clearly dominates the model results. At a depth of `max_depth = 13`, the model overfits roughly 7 percentage points, with validation accuracy limited to ~63%.\n",
    "\n",
    "In this case, I will take the parameters `max_depth = 10` and `n_estimators = 20`. The model still overfits roughly 3 percentage points, but it results in a validation accuracy of 61.41%, which is on a higher level than the next best results with maximum depths of 7 and still present overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>0.778034</td>\n",
       "      <td>0.645870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0.779930</td>\n",
       "      <td>0.645025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.782459</td>\n",
       "      <td>0.642165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.778485</td>\n",
       "      <td>0.641646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.783023</td>\n",
       "      <td>0.637616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.637356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.681905</td>\n",
       "      <td>0.635601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.698002</td>\n",
       "      <td>0.634302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.684931</td>\n",
       "      <td>0.632092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.650119</td>\n",
       "      <td>0.630467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rf__max_depth  rf__n_estimators  train_acc   val_acc\n",
       "24             13                50   0.778034  0.645870\n",
       "23             13                40   0.779930  0.645025\n",
       "21             13                20   0.782459  0.642165\n",
       "22             13                30   0.778485  0.641646\n",
       "20             13                10   0.783023  0.637616\n",
       "19             10                50   0.686421  0.637356\n",
       "18             10                40   0.681905  0.635601\n",
       "15             10                10   0.698002  0.634302\n",
       "16             10                20   0.684931  0.632092\n",
       "10              7                10   0.650119  0.630467"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B term\n",
    "# loop through all combinations\n",
    "\n",
    "# save results\n",
    "rf_results_b = []\n",
    "\n",
    "for params in rf_grid:\n",
    "    rf_pipe.set_params(**params)\n",
    "    \n",
    "    # fit pipe\n",
    "    rf_pipe.fit(X_tr_b, y_tr_b)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    val_acc = rf_pipe.score(X_val_b, y_val_b)\n",
    "    train_acc = rf_pipe.score(X_tr_b, y_tr_b)\n",
    "    \n",
    "    # append accuracy to param_max_depth\n",
    "    params[\"val_acc\"] = val_acc\n",
    "    params[\"train_acc\"] = train_acc\n",
    "    \n",
    "    # append param_max_depth to dt_results\n",
    "    rf_results_b.append(params)\n",
    "    \n",
    "# transform list to DataFrame\n",
    "rf_results_b = pd.DataFrame(rf_results_b)\n",
    "rf_results_b.sort_values(by = \"val_acc\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>0.778034</td>\n",
       "      <td>0.645870</td>\n",
       "      <td>0.132164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0.779930</td>\n",
       "      <td>0.645025</td>\n",
       "      <td>0.134905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.782459</td>\n",
       "      <td>0.642165</td>\n",
       "      <td>0.140293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.778485</td>\n",
       "      <td>0.641646</td>\n",
       "      <td>0.136840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.783023</td>\n",
       "      <td>0.637616</td>\n",
       "      <td>0.145407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.637356</td>\n",
       "      <td>0.049064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.681905</td>\n",
       "      <td>0.635601</td>\n",
       "      <td>0.046304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.698002</td>\n",
       "      <td>0.634302</td>\n",
       "      <td>0.063700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.684931</td>\n",
       "      <td>0.632092</td>\n",
       "      <td>0.052839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.650119</td>\n",
       "      <td>0.630467</td>\n",
       "      <td>0.019651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rf__max_depth  rf__n_estimators  train_acc   val_acc      diff\n",
       "24             13                50   0.778034  0.645870  0.132164\n",
       "23             13                40   0.779930  0.645025  0.134905\n",
       "21             13                20   0.782459  0.642165  0.140293\n",
       "22             13                30   0.778485  0.641646  0.136840\n",
       "20             13                10   0.783023  0.637616  0.145407\n",
       "19             10                50   0.686421  0.637356  0.049064\n",
       "18             10                40   0.681905  0.635601  0.046304\n",
       "15             10                10   0.698002  0.634302  0.063700\n",
       "16             10                20   0.684931  0.632092  0.052839\n",
       "10              7                10   0.650119  0.630467  0.019651"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results_b[\"diff\"] = rf_results_b[\"train_acc\"] - rf_results_b[\"val_acc\"]\n",
    "rf_results_b.sort_values(by = \"val_acc\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the B-term model overfits even stronger at `max_depth = 13` with train accuracies around 78% and validation accuracies still limited to 64.5%.\n",
    "\n",
    "In this case, I will take the combination of `max_depth = 7` and `n_estimators = 10`. This results in only ~2 percentage points overfitting while maintaining a validation accuracy of 63%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>0.761830</td>\n",
       "      <td>0.666025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.764296</td>\n",
       "      <td>0.665938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0.761910</td>\n",
       "      <td>0.665194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.761157</td>\n",
       "      <td>0.664319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.756385</td>\n",
       "      <td>0.660821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.703396</td>\n",
       "      <td>0.654829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.701171</td>\n",
       "      <td>0.652554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.703220</td>\n",
       "      <td>0.652467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.695053</td>\n",
       "      <td>0.650542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.684949</td>\n",
       "      <td>0.641051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rf__max_depth  rf__n_estimators  train_acc   val_acc\n",
       "24             13                50   0.761830  0.666025\n",
       "22             13                30   0.764296  0.665938\n",
       "23             13                40   0.761910  0.665194\n",
       "21             13                20   0.761157  0.664319\n",
       "20             13                10   0.756385  0.660821\n",
       "17             10                30   0.703396  0.654829\n",
       "19             10                50   0.701171  0.652554\n",
       "18             10                40   0.703220  0.652467\n",
       "16             10                20   0.695053  0.650542\n",
       "15             10                10   0.684949  0.641051"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# J term\n",
    "# loop through all combinations\n",
    "\n",
    "# save results\n",
    "rf_results_j = []\n",
    "\n",
    "for params in rf_grid:\n",
    "    rf_pipe.set_params(**params)\n",
    "    \n",
    "    # fit pipe\n",
    "    rf_pipe.fit(X_tr_j, y_tr_j)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    val_acc = rf_pipe.score(X_val_j, y_val_j)\n",
    "    train_acc = rf_pipe.score(X_tr_j, y_tr_j)\n",
    "    \n",
    "    # append accuracy to param_max_depth\n",
    "    params[\"val_acc\"] = val_acc\n",
    "    params[\"train_acc\"] = train_acc\n",
    "    \n",
    "    # append param_max_depth to dt_results\n",
    "    rf_results_j.append(params)\n",
    "    \n",
    "# transform list to DataFrame\n",
    "rf_results_j = pd.DataFrame(rf_results_j)\n",
    "rf_results_j.sort_values(by = \"val_acc\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>0.761830</td>\n",
       "      <td>0.666025</td>\n",
       "      <td>0.095805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0.764296</td>\n",
       "      <td>0.665938</td>\n",
       "      <td>0.098358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0.761910</td>\n",
       "      <td>0.665194</td>\n",
       "      <td>0.096716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.761157</td>\n",
       "      <td>0.664319</td>\n",
       "      <td>0.096838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.756385</td>\n",
       "      <td>0.660821</td>\n",
       "      <td>0.095565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.703396</td>\n",
       "      <td>0.654829</td>\n",
       "      <td>0.048568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.701171</td>\n",
       "      <td>0.652554</td>\n",
       "      <td>0.048616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.703220</td>\n",
       "      <td>0.652467</td>\n",
       "      <td>0.050754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.695053</td>\n",
       "      <td>0.650542</td>\n",
       "      <td>0.044511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.684949</td>\n",
       "      <td>0.641051</td>\n",
       "      <td>0.043897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0.648902</td>\n",
       "      <td>0.629636</td>\n",
       "      <td>0.019266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.647493</td>\n",
       "      <td>0.627843</td>\n",
       "      <td>0.019650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0.644210</td>\n",
       "      <td>0.622857</td>\n",
       "      <td>0.021353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.640495</td>\n",
       "      <td>0.619052</td>\n",
       "      <td>0.021443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.641040</td>\n",
       "      <td>0.617302</td>\n",
       "      <td>0.023737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rf__max_depth  rf__n_estimators  train_acc   val_acc      diff\n",
       "24             13                50   0.761830  0.666025  0.095805\n",
       "22             13                30   0.764296  0.665938  0.098358\n",
       "23             13                40   0.761910  0.665194  0.096716\n",
       "21             13                20   0.761157  0.664319  0.096838\n",
       "20             13                10   0.756385  0.660821  0.095565\n",
       "17             10                30   0.703396  0.654829  0.048568\n",
       "19             10                50   0.701171  0.652554  0.048616\n",
       "18             10                40   0.703220  0.652467  0.050754\n",
       "16             10                20   0.695053  0.650542  0.044511\n",
       "15             10                10   0.684949  0.641051  0.043897\n",
       "13              7                40   0.648902  0.629636  0.019266\n",
       "14              7                50   0.647493  0.627843  0.019650\n",
       "12              7                30   0.644210  0.622857  0.021353\n",
       "11              7                20   0.640495  0.619052  0.021443\n",
       "10              7                10   0.641040  0.617302  0.023737"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results_j[\"diff\"] = rf_results_j[\"train_acc\"] - rf_results_j[\"val_acc\"]\n",
    "rf_results_j.sort_values(by = \"val_acc\", ascending = False)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model overfits less than the B-term, which is a development we haven't seen until now. We also reach validation accuracies in the ranges of 66.6%, which is higher than the decision tree and random forest models. Nevertheless, the model overfits 9.5 percentage points at that stage, which makes the scores again faulty in future generalization attempts.\n",
    "\n",
    "For the J-term model, I will use the combination of `max_depth = 7` and `n_estimators = 40`, which gives us a validation accuracy of 62.96% with just below 2 percentage points overfitting.\n",
    "\n",
    "We will now evaluate our tuned models on the actual test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest accuracy of combined model = 0.6279\n",
      "random forest accuracy of B-term = 0.6456\n",
      "random forest accuracy of J-term = 0.6110\n"
     ]
    }
   ],
   "source": [
    "# evaluate tuned models on test set\n",
    "\n",
    "# combined model\n",
    "pipe_rf = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"rf\", RandomForestClassifier(max_depth = 10, n_estimators = 20, random_state = 0))])\n",
    "\n",
    "pipe_rf.fit(X_tr, y_tr)\n",
    "\n",
    "rf_acc = pipe_rf.score(X_te, y_te)\n",
    "print(\"random forest accuracy of combined model = {:.4f}\".format(rf_acc))\n",
    "\n",
    "# B term\n",
    "pipe_rf_b = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"rf\", RandomForestClassifier(max_depth = 7, n_estimators = 10, random_state = 0))])\n",
    "\n",
    "pipe_rf_b.fit(X_tr_b, y_tr_b)\n",
    "\n",
    "rf_acc_b = pipe_rf_b.score(X_te_b, y_te_b)\n",
    "print(\"random forest accuracy of B-term = {:.4f}\".format(rf_acc_b))\n",
    "\n",
    "# J term\n",
    "pipe_rf_j = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"rf\", RandomForestClassifier(max_depth = 7, n_estimators = 40, random_state = 0))])\n",
    "\n",
    "pipe_rf_j.fit(X_tr_j, y_tr_j)\n",
    "\n",
    "rf_acc_j = pipe_rf_j.score(X_te_j, y_te_j)\n",
    "print(\"random forest accuracy of J-term = {:.4f}\".format(rf_acc_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final results for the random forest classifier are:\n",
    "* Combined set:\n",
    "    * train: 64.39%, val: 61.41%, test: 62.79%\n",
    "* B term:\n",
    "    * train: 65.01%, val: 63.05%, test: 64.56%\n",
    "* J term:\n",
    "    * train: 64.89%, val: 62.96%, test: 61.10%\n",
    "    \n",
    "Every single model here has a generalization problem. The combined model overfits roughly 1.5 percentage points, the B-term overfits again the least with only 0.5 percentage points, and the J ther overfits again the most with almost 4 percentage points. \n",
    "\n",
    "The B-term also has the best performance here, which could be that the B-term has more \"focussed\" data that allows the algorithm to find more concise trends and thus create better predictions. However, in simple decision trees, the B-term was the worst performing model with 64.08% accuracy. \n",
    "\n",
    "All in all, random forests couldn't negate the problem of overfitting and couldn't consistently beat the simple decision tree results. \n",
    "\n",
    "In simple decision trees, the worst performing model had an accuracy of 64.06%, here we are down to 61.10%. On one hand, we are able to consistently beat the most-frequent baseline, but in the end we received models that overfit more strongly than simple decision trees and thus generalize worse on previously unseen test data.\n",
    "\n",
    "We will now evaluate and discuss the predictions more deeply with a confusion matrix and classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: Fail</th>\n",
       "      <th>pred: Withdrawn</th>\n",
       "      <th>pred: Pass</th>\n",
       "      <th>pred: Distinction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: Fail</th>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>5773</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: Withdrawn</th>\n",
       "      <td>0</td>\n",
       "      <td>1081</td>\n",
       "      <td>5017</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: Pass</th>\n",
       "      <td>48</td>\n",
       "      <td>117</td>\n",
       "      <td>23922</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: Distinction</th>\n",
       "      <td>8</td>\n",
       "      <td>934</td>\n",
       "      <td>3069</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred: Fail  pred: Withdrawn  pred: Pass  pred: Distinction\n",
       "true: Fail                 68                4        5773                  4\n",
       "true: Withdrawn             0             1081        5017                383\n",
       "true: Pass                 48              117       23922                 38\n",
       "true: Distinction           8              934        3069                912"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# get predictions in array\n",
    "rf_preds = pipe_rf.predict(X_te)\n",
    "\n",
    "# create confusion matrix\n",
    "rf_matrix = confusion_matrix(y_true = y_te, y_pred = rf_preds)\n",
    "\n",
    "# convert matrix to DataFrame\n",
    "rf_matrix_df = pd.DataFrame(data = rf_matrix, columns = [\"pred: Fail\", \"pred: Withdrawn\",\n",
    "                                                                \"pred: Pass\", \"pred: Distinction\"],\n",
    "                               index = [\"true: Fail\", \"true: Withdrawn\", \"true: Pass\", \"true: Distinction\"])\n",
    "rf_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.01      0.02      5849\n",
      "           1       0.51      0.17      0.25      6481\n",
      "           2       0.63      0.99      0.77     24125\n",
      "           3       0.68      0.19      0.29      4923\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     41378\n",
      "   macro avg       0.59      0.34      0.33     41378\n",
      "weighted avg       0.61      0.63      0.53     41378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# print classification report to see recall and precision scores\n",
    "rf_report = classification_report(y_true = y_te, y_pred = rf_preds)\n",
    "print(rf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that this estimator is also heavily biased in favor of `Pass`. \n",
    "\n",
    "We reach again a recall score of 97% for class `2`, but this time we do have at least some predictions of `Fail` values. Then again, only 1% of the true values are predicted by the model, so it is still a model with very high false negativity rate.\n",
    "\n",
    "This model reaches a 68% precision score for class `3`, i.e. `Distinction`. At first this may sound good that 68% of our `Distinction` predictions are correct, the recall score of 19%, however, shows that only around $\\frac{1}{5}$ of all actual `Distinction` finishing students were recognized. The same is true for 17% regarding class `1`, and again only 1% for class `0`, i.e. `Fail`. \n",
    "\n",
    "#### Main problem of the model\n",
    "Like in all of our models, the recall score of 1% for class `Fail` enables the students to feel more comfortable about their performance than they should be. In a good model, this false negativity rate in which positive = `Fail` and negative = `Pass` should be reduced. It is more acceptable to predict `Pass` when the student is finishing with `Distinction` than it is to predict `Pass` when the student withdraws or fails. \n",
    "\n",
    "The ROC-curve will again visualize the problem of this model's classification between `Pass` and `Fail` in a simplified binary setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VNX9//HXOwlJgBC2sMmu7O6CVK1arEupS+2iFbeqtVXbr/br2p9ttfVrl6/VtrZWq/Xrbq1r1aLiUhfcQUB2EGUnIBAgIYQl23x+f9ybOAyTZBIymSTzeT4eeTB37pl7P3dmmM8959x7jswM55xzDiAj1QE455xrPTwpOOecq+VJwTnnXC1PCs4552p5UnDOOVfLk4JzzrlanhRck0gaKWm2pG2SfpLqeJqLpDclnRU+vkzS6y2032mSzmuJfdW3b0kXS3ohFXG0ZvV9PpJGSapq6ZiSxZMCIGmlpJ2SyiStl/SQpLyYMkeFPxjbJG2V9IKkMTFl8iX9WdLqcFtLw+WCevY9QtLTkjaF250n6WpJmck63mbyU2CqmXUxszuiV0haGB5/maRqSbuiln+e7MAkZUkySduj9rspkdea2VfN7Mlkx9gYkm6RVBkeR4mk9yQdnox9mdn9ZnZagjHd10CZyyRVhXGXSvpY0sTmi7befY8KvwM1n/9ySde0xL7bOk8KXzjNzPKAQ4BDgZ/VrJB0JPAa8G9gH2AoMBd4X9K+YZls4A1gf2AikA8cBWwGxsfboaT9gOnAGuBAM+sKnAmMA7o09gAkZTX2NXthMLAw3goz29/M8sL3813g8pplM/tdbPkkxr1/1H7rTMxtxMPh+9kbmAU8Ha9QC38HEjE1jLs78DjwdOwJVxJVR30PLwR+J2lCbKFW+J6llCeFGGa2HniVIDnUuBV4xMz+YmbbzGyLmd0ATANuCst8DxgEfMvMFplZxMw2mtmvzWxKHbv7H+ADM7vazD4P97/EzM4xsxJJEyQVRr8grNWcED6+SdIzkv4hqRT4eVjj6RFV/tCwFtIhXP6+pMWSiiW9KmlwXe+FpG+EZ/0lkqZKGh0+/yZwHHBneBY2IqE394vt/kDSO5LukLQFuEHSbyQ9FFVmmCSLWu4m6UFJn0sqlHSzpEZ/fyX1kvSypCJJWyT9W1K/qPUJNeOEtZF/SdoQvj9vSRoZtf6JsJb4ali7fD/6vZZ0iqTPwtf+KdH4zawCeAQYLCkvPBt/U9JdkoqB68PtXyppSXiML0nqn8i+FdNkJungcPvFCmrR10j6JnA1cEH4+X+UQNzVwANAHjAkgc/hh+F3fVt4ln9m+PyosKa0NXztIwm+b+8AnwIHSMoNaxE/krQMWBBu+ythbWZr+D2IrY2NlDQrXP8vSV3j7UtSD0mPhO/XGkm/qvmuRn1ed4bb+UzSOEmXSFobfp8mJXJMyeJJIYakAcDXgaXhcieCM/54Z2ZPASeGj08AXjGzskbs7gTgmaZHC8Dp4Ta6AbcBHwLfiVp/DvCMmVWG/5l/Dnwb6EVwFv94vI2GP/SPA1eGZacAL0jKNrOvsnsN4NMmxH0UsDjc9u8TKP8PYCewH0FN6hTgoibsNwO4hyCBDw2fu70J2wGYHMbTF/gEeDhm/TkENc4ewOcEJwFI6kvw3bmG4PiLCI6pQZJygQuApVHftWOBOUAB8MfwR+VK4DSgDzCb4P1r1L4ldQdeB54Nj3EE8I6ZPQ/8ibD2YmZxa8Ix28oCLga2Aiuo53MI93sbcLyZdQGOIfzhBv4XeJ7g+z4I+HsC+5aCGsIIgvepxqnAWOBQSb2BF4BbgJ5hbFNifvi/B5wL9AeygT/WscvHwuPcl6CV4JvA+VHrjwE+CPfzPPAvYHT4PvwQuDv8nFPDzNL+D1gJlAHbACNoBuoWrhsQPjcqzusmApXh4/8AtzRyv5XAxHrWTwAK48R6Qvj4JoL/pNHrfwC8GT4WQdPUseHyy8DFUWUzgB3A4Dj7vhF4KqbsWmBCuDwV+EECx7hHuTDG5THP/QZ4KGp5WPD1NAj+E+4EcqLWnw/8p459ZoWfWSlQEv79qY6yRwCfRy1PA84LH18GvJ7gZ9kXiAC54fITwJ1R678NzAkfX0LQrFKzLhPYWLPfONu+BSgPj2Nj+F07KCrGT2PKvwWcG7XcIfyu9Wlo39HHTJB0P6wnpvsaeE8uC/dbAmwC3q/5/tT3ORA0NZUQnPDkxpR7CrgT6NfAvkeF34ESoBhYBFwWrssN1x0VVf6H7Pl/aTYwKep7cVPUusOA7VH7qgofDwa2Ax2iyl4EvBz1nsyPWnd4GEvXqOe2E+f3pqX+vKbwhW9acFYygeBDrmmDLib4z94vzmv6EXzZIeg7iFcGAEnn6otOr5cTeU2C1sQsPwMcKWkfgjNIIzirh+AL+5ew2aAE2EKQOPqzp32AVTULZhYJ9xWvbHPEXZ/BQA6wISr2uwh+5AibSWre2yOjXneQmXUL/64Oy3aR9ICCiwFKCfqKGt3fEDYf/SFs2iglqCmI4OyvxvqoxzsImk4geG9rj9+CppW1Dezy0fA4epvZiWY2L2pd7Hs5GLgn6r0qAqoITnAas++BwLIG4gJA0glRn8GsqFVvh3EXmNmXzWxqWL7Oz8HMignOyH8CrJc0WdKwcHtXAZ2A2Qouyqivqa863Hd3MxtjZvfErI9+33b7vodWsfv3fU3Muk5xmpAGEySdoqj3/y+E39XQhqjHO4FyM9sa81xL9bvswZNCDDN7G3gI+EO4vJ2gSebMOMW/S1CrgKCa/TVJnevY7mP2Rafn16Ne85145UPbCf4DAKDgiqResZuO2U8JwX+w7xI0Xzxu4ekHwZf60qgfym5m1tHMPoiz73UEX/CafYvgR6KhH69ExQ7Pu9uxEpx511hD8KPaIyrufDM7CMDMRka9tx82sN/rCX4cDzezfOAkgh/zxroofO1xQFeCEwkS3NbnBO9l8IKgvXlvkm3se7kGuDDO5zyrkfteQ9A81uA+zez1qM9gbAIx1/s5mNlLZnY8wY/1auDu8Pm1ZvZ9gpOpnwAPSBqUwP4aOobdvu+hQez+fR8Ys25HzI85BO9ZGdA95rt6WBNjbHGeFOL7M3CipJrO5usJOtV+Ep7hdJf0G+BIwnZi4FGCL8S/ws6wDEk9Jf1c0sl17OdXwFGSbgvbems6WP8hqRtBx1iugo7BDsANBGfMDfknQfvnd8LHNe4BfiZp/3BfXWs68OJ4CjhF0vHhvq8haMKIl0CawxzgK5IGhsd+fc0KM1sDvA38QcFlvxnh+3RsE/bThSDBlCi4VPiGJsbbBdhFUNvrTND8lajJwOGSTg3f2+sI+h2ayz0EnfcjIWijl1Rz8tGYfT8PDAs7ZLPD976m83UDMDQ8WWiKOj8HSf3D73wngu9cGVAdrjtL0j7hiU5J+JLmuEdgMkHfwhlhLbDmwpFXospcqOAS8jyCpts9Ll02sxUETU23hr8VGZKGSzq6GWJsEZ4U4jCzIoIrPG4Ml98DvkbQLvw5QdXxUOBoM/ssLFNO0HH8CUGbbynwEUGVeHod+1lGkFiGAAslbSXodJoJbAvPQn4M3EdwxrIdKIy3rRiTgeHABjObG7W/5wg6dZ8Iq+wLCDrV48W2BDgP+CtBE9lpBJftViSw/6Z4BXgOmE/wvk2OWX8ewY/vIoImvafZvTaRqD8QfCabgfcIOtCb4n6CZpn1BDG/l+gLLbjSbBLByUcRQdPCzCbGEW/7jxO0uz8bfs5zCC+IaMy+w2acE8PyG4ElQM2P2xMENbstkppyolDf55BJ0EG/Plx/OHBFuO5IYJakMoLvwCVmtq4J+9+NmW0AvgH8Itzn5cCpYc27xqMEF1+sJWhSruu+h7MJOsI/IWiifZLdm49aNX3RsuCccy7deU3BOedcLU8KzjnnanlScM45V8uTgnPOuVptbiCogoICGzJkSKrDcM65NmXWrFmbzCz2Pqc9tLmkMGTIEGbObLar95xzLi1Iir1jOy5vPnLOOVfLk4JzzrlanhScc87V8qTgnHOulicF55xztZKWFMKx0jdKWlDHeimYjnFpOC56mxla1jnn2qtk1hQeIpiZrC5fJxjJczjBbFB3JzEW55xzCUjafQpm9o6kIfUUOR14JBwXfZqCidn7hUP7OudcizIzqiNGtRmRCFSHy5Ha54ztFdVEzKiqNqoiEaojRmV1hM1lFWRlioqqYHldyU46ZWdigFmw7YgRLgcjU0fMgnVhmUj4vIXPB+WjyxgnjO7DwQO7JfV9SOXNa/3ZfXq7wvC5PZKCpEsIahMMGtTUSZacc23dtl2V7KqMUFEdoXRnJTsqqli4rpTt5dV8sr6Ujh0yqawOfpirIhFWbd5BXk4WFdURlm0so0tuB8yMqogFP+4Ro7ra2FbeHPP0JJcEfbvmtuukEG/GpriTO5jZvcC9AOPGjfMJIJxrJyIRY+Xm7WzbVUV5VYQNpbvIzBAVVREqqiJ8umEbxTsqWbhuK59tLKM6Uvd//wwFZ9f9u3UkK1NkZYgOmRks3VjGmH3yGT+0J5u3lzOsVx6ZGSIzIyiTEf67uayCwT07k5UpMiQyMwj/Df4yJEp3VQbbz8io3UdmhqisNnp1ySE7M4PsLJGVkUHH7EwyM4QItiOBECiIVQrWScF6wsdCe6xv+gR3jZfKpFDI7nOeDiCYJ9U514aVlVcxd00JpTsr2bitnI9WbiEnM4PF67eRn5tFVcRYv3UXZeVVbN1ZmdA283Oz2H+ffA4Z2I3hfbqQk5lBdlYGEvTJz2V47zx6dM5u0R/P9iqVSWEycLmkJ4AvAVu9P8G51q28qppNZRUUbtlB6a4qlheVIcGS9WWsK9nJmuIdFBbvjPvakX26sHLzdob1zmNY7zxKdlQwZp+udM7OZOzg7uR37ECGRJfcLDplZ5KdlUFOViYFef5j35KSlhQkPQ5MAAokFRJMUt8BwMzuIZiT9WRgKcEE3hclKxbnXOPsqKjik/XbWLV5OwvXlvL+ss0s/ry0wdd9ZUQvTj6wHyP6dGFY7zz65OdQkJdDh0y/JaqtSObVR2c3sN6A/0rW/p1zdYtEjMXrS1m/dRfrtu6ivLKasvIqZq4s5r2lm3YrK8HgHp0Y2KMjI/t04cvDCuick8U+XTuyT7dcCrrk0Dk7i8wMP5tvD9rc0NnOucTMWVPCO58WMXt1MbsqIxSVlVOyo4LyykidV9vk5WTRrVMH+ubncu4Rgxk7qDtDCjrRKdt/KtKFf9LOtXHVEWPOmmK27qxk9uoSZq4s5qOVW3a7UiczQxy1X0/GDe5Ox+xMcrIyycvJ5PAhPejfvSP5HTuQk5VBdmaGt9+nOU8KzrUxkYjx1pKNLCsqY86aEqbMX79HmdwOGXxpaA+uPnEEYwd39x96lzBPCs61YmXlVbz3WRGFxTuZs6aERetKWb5pe+367MwMRvbpwoRRvTh2eC/65OcwuGdn79h1TeZJwblWoqo6wtzCrTw3u5D5a0tZuWl73Ov4D+ifz5eG9uScLw1iaM/OZHgHr2tGnhScS4FdldVMX7GFZRvLWLB2KzNWbWHTtgp2VlYDwc1aBXk5jB3cnVMO7MfYwd3Zp1tHsrO8BuCSy5OCc0lUHTFWbNrOgrVbmb5iM8uKtvPxqmKq4gzX0Cc/h+u+NpKjhxcwok+XFETrnCcF55pdZXWEJ2asYc7qEp6dXYjF/P737pJDl9wszh4/iCP368mYfvneEexaDU8Kzu0lM+PD5Zt5c/FG1pfu4sV5u4/Wcumx+3LEvj3Zf598eufnpihK5xLjScG5RjAzdlVGWLqxjBfnr+ODpZuZv3brbmW+tn8fxvTryqVf2ZfcDpkpitS5pvGk4FwDdlVW88Lcdbz72SZeW7SeXZWR3dYfNqgb+/XK49qvjaSP1wRcG+dJwbkYs1cX88Gyzby2aANri3eyqay8dt3gnp349qEDyMoUJ43pw3DvEHbtjCcFl/bMjOkrtnD/eytYv3VXbXNQdmYGvbrkcMLo3rWjf/bMy0lxtM4llycFl7bWb93F76Ys5uUFn1NZ/cUlQpceuy/nHzmYAd07pTA651LDk4JLK2bG83PWcuebS1lW9MVwEWeMHcAPjhnKqL75KYzOudTzpODSRumuSi59ZBYfLt8MQL+uufzqtP2ZeEDfFEfmXOvhScG1e1t3VnLbq5/wj2mrAfjqqN7c8u0D/Z4B5+LwpODaJTPj5QXreWn+57z1yUZ2VARjCv104kh+PGFYiqNzrvXypODalUjEeGHeOv7w2hLWbAkmkO/frSN/+u5oJh7QL8XROdf6eVJw7caTM1Zz37sr+GxjGTlZGZxyUD9uO+Mgn0rSuUbw/y2uzXvn0yKufXouG7cFN5ld+pV9+enXRvlE8s41gScF12btrKjmj68t4b73VgDBFJRzfnmSjzfk3F7wpODanPKqam5+YRFPzFhDdcTYr1dn7rvgcIYWdE51aM61eZ4UXJuxvbyKv765lPvfW05ltdElJ4vbzzqEE8b0SXVozrUbnhRcq1ZzB/JL89bz+uINABTk5XDDKaP55qH9Uxydc+2PJwXXar21ZCOXPjKLiupgqOqJ+/floIFd/T4D55LIk4JrdcrKq7ju6bm8vGA9AGePH8QvTx1Dx2zvQHYu2TwpuFZhy/YKnpq5hkXrSpk8d13t809deiTjh/ZIYWTOpRdPCi6lqiPGX974jDve+Kz2uf7dOjLxgL7ceOqYFEbmXHrypOBS5p1Pi7j00VnsrAzGJbr/gnEcO6IXHTIzUhyZc+nLk4JrcWu27OB/X17MlPlBn8HQgs68/N/H+E1nzrUCSU0KkiYCfwEygfvM7JaY9YOAh4FuYZnrzWxKMmNyqWNm3P767k1F8246ifzcDimMyjkXLWlJQVImcBdwIlAIzJA02cwWRRW7AXjKzO6WNAaYAgxJVkwudVZu2s5P/zWPj1ZsYUSfPP703UM4oH/XVIflnIuRzJrCeGCpmS0HkPQEcDoQnRQMqJn/sCuwDteuFBbv4M+vf8YzswoBOGhAV57/8ZfJ8MHqnGuVkpkU+gNropYLgS/FlLkJeE3SFUBn4IR4G5J0CXAJwKBBg5o9UJccz89ey5VPzgGgR+ds7j1/LOOG+OWlzrVmyUwK8U4FLWb5bOAhM/ujpCOBRyUdYGaR3V5kdi9wL8C4ceNit+Faod+/8gl3T10GwB/PPJjvjB2Q4oicc4lIZlIoBAZGLQ9gz+ahi4GJAGb2oaRcoADYmMS4XBJVVke48sk5vDTvcwDevm4Cg3v66KXOtRXJTAozgOGShgJrgUnAOTFlVgPHAw9JGg3kAkVJjMkl0asL13Pd03Mp3VUFwIxfnECvLjkpjso51xhJSwpmViXpcuBVgstNHzCzhZJuBmaa2WTgGuD/JF1F0LR0oZl581AbU1Ud4dcvLuLhD1cBMGFkLx644HDvTHauDUrqfQrhPQdTYp77ZdTjRcCXkxmDS64X5q7jNy8tYkNpOYN7duKpS4+kT35uqsNyzjWR39HsmuSDpZu4/fVPmbGymAzBxUcP5WdfH0WWD1HhXJvmScE1ytw1Jfzi+fksWFsKwMAeHZl67XFkelORc+2CJwWXkKJt5fz4sVnMWFlMXk4WFxw5mMu/Otw7kp1rZzwpuHpFIsatry7hnreDew6OH9WbW884iJ55ngyca488Kbg6mRk3/nsBj01fTefsTG4782BOPrBfqsNyziWRJwUX17qSnZx3/3SWF23nyH178s8ffgnJ+w2ca+88Kbg9TJn/OVc+MYeK6gjHjezF3eeN9YTgXJpoMClI6ghcCQw2s8skDQOGm9nLSY/OtajqiHHD8/N5/KM1DOjekb9MOoSxg30AO+fSSSI1hQeA+cDR4fI64GnAk0I78t5nmzjv/ukADOrRiReuOJquHX3yG+fSTSJJYbiZnS3pTAAz2yFvS2g3IhHjzreW8qf/fArAKQf1465zDktxVM65VEkkKVSEo5caQDjAXUVSo3ItYnt5FVc9OYfXFm0A4K1rJzC0wEc0dS6dJZIUfg28AgyQ9DDwFeAHSY3KJV1h8Q6+9bcPKNpWzldH9eaucw6jY3ZmqsNyzqVYg0nBzF6WNBM4imDinOvMzOc7aMNufH4Bj05bhQS//86BnHW4z2bnnAskcvXRa2Z2EvDvOM+5NuaNxRt4dNoqsrMyeOW/j2HfXnmpDsk514rUmRQkZRNMetNHUhe+mF4zH/BTyzZo8tx1/OTx2fTJz+Ht644jt4M3FznndldfTeG/gKuB3sBCvkgKpcA9SY7LNbPXFq7n2qfnAvDQReM9ITjn4qozKZjZ7cDtkq40sz+3YEyumT01Yw0//dc8wK8wcs7VL5GO5j9LGgWMIWhOqnn+n8kMzO29XZXVXP3UHKbMXw/Auz89joE9OqU4Kudca5ZIR/MNwEnAKIL5lr8GvAd4UmjFtu6s5Ky/f8gn67cxbnB3HrzocLrk+h3Kzrn6JXKfwlnAIcDHZna+pH7A35MbltsbC9dtZdLfp7GtvIpfnjqG7x89NNUhOefaiEQm1N1pZtVAVXgV0npg3+SG5Zrqk/WlnHLHe1RURzwhOOcaLZGawmxJ3QgGxptJcPXRx0mNyjXJ5rJyfvyPj8nOzOBlvwfBOdcEiXQ0Xxo+vEvSq0C+mXlSaGU2l5Vzwp/epnhHJT+esJ8nBOdckyTSfFTLzJYCpZLuTlI8rgm2l1cx6d5pFO+o5O5zD+OnE0elOiTnXBtVZ1KQdICkKZLmSLpJUi9JTwLvAMtbLkRXn+LtFVz2j1l8trGMK08Yztd9DmXn3F6or/novvDvQ2AiQT/C08B+ZrazBWJz9YhEjOufncdzs9dSHTF+ddoYLvqydyo75/ZOfUkh18zuCx8vlHQl8FMzq2qBuFwDHp22iqdmFjKsdx6//eYBfGnfnqkOyTnXDtSbFCQdyBdjHpUBo2tmXTOzeckOzsW3qayc37y0iE7Zmbx25bFkZPhEeM655lFfUigC/ha1vClq2YBjkxWUq5uZMeneaVRWG3dMOtgTgnOuWdU3IN4xLRmIS8z/vLCIpRvLOHpYgXcqO+eaXaMuSW0sSRMlLZG0VNL1dZT5rqRFkhZK8vGU6vHIhyt56IOV7NM1lwcvOjzV4Tjn2qFE7mhuEkmZwF3AiUAhMEPSZDNbFFVmOPAz4MtmViypd7LiaeuWbizjNy8uBmDqdcfRITOp+dw5l6aS+csyHlhqZsvNrAJ4Ajg9pswPgbvMrBjA536u2zVPz6WiOsI/f/AlsrM8ITjnkqPBXxdJT0j6Ws1VR43QH1gTtVwYPhdtBDBC0vuSpkmaWEcMl0iaKWlmUVFRI8No+16ct465a0o4elgBRw0rSHU4zrl2LJFTzoeA7wOfSvqNpGEJbjteErGY5SxgODABOBu4Lxx8b/cXmd1rZuPMbFyvXr0S3H37UFi8g6uenAPA3847LMXROOfauwaTgpm9YmZnETQHrQfekvSOpPMl1dcnUQgMjFoeAKyLU+bfZlZpZiuAJQRJwgElOyo4977pVFYbD110OPk+SY5zLskSapyW1B04BzgfmEcwyc5RwCv1vGwGMFzSUEnZwCRgckyZ54Hjwn0UEDQn+bhKoQsfnMGqzTu457yxTBjpffDOueRLZDrOp4ADCabf/I6ZFYarHpM0u67XmVmVpMsJpvDMBB4ws4WSbgZmmtnkcN1JkhYB1cB1ZrZ57w6pfTAzVm3eDsDEA/qmOBrnXLpI5JLU+4D/mFltf4CkLDOrMrND63uhmU0BpsQ898uoxwZcHf65KI9NX03xjkouPGpIqkNxzqWRRJqPbolOCKGPkhGMCywvKuN/XljI+CE9+PnJo1MdjnMujdRZUwhvJOsHdIwZGC8f6NQCsaWlyuoI3777AyqrjetPHuX3JDjnWlR9zUenEFyKOoDdB8bbBtyYzKDS2Y3PL6BkRyUT9+/LYYO6pzoc51yaqW9AvAeBByV918yeasGY0taaLTt4elYhA7p35G6/J8E5lwL1NR+dbWaPA/0k/SR2vZndkdTI0kwkYlzx+GyqI8bD3x9P428gd865vVdf81FN24WPq9ACfjtlMXPWlHDTaWPYr1deqsNxzqWp+pqPavoRbjezLS0UT1q6e+oy7n9vBQAX+CWozrkUSuTSlhmSpki6QFJ+0iNKM098tJrfv/IJo/p2Yf5NJ3mzkXMupRIZ+2g/4DfAWGCepOclTUp6ZGlgZ0U1f3jtU7p36sALVxxNFx/byDmXYgldBG9mH5jZT4DDgFLgsaRGlQYqqyN89Y9T2VRWzm+/daBPmuOcaxUSmU8hT9K5kl4guJO5iGAwPLcX7n9vBZ9v3cXYwd052edads61EomMfbQAeAG41czeTXI8acHMuO/dYDDYpy89MsXROOfcFxJJCvuaWSTpkaSRv765lE1lFVx94ggyMrxj2TnXetR389ofzewa4F+SYgfEw8y+ndTI2qnSXZXc8/YyhvfO44qvJjqJnXPOtYz6agpPhv/e2RKBpIv/98w8dlRUc8OpY/zyU+dcq1PfzWs1w2OPNrPdEkM4ec4byQysPfrHtFW8vGA9Bw/sxrHD/UZx51zrk8h1kN+P89zFzR1Ie7dx2y5+N2UxnbMzefKSI7yW4JxrlerrUziLYF7loZKejVrVBShJdmDtiZkx/rdBxeqZy44kt0NmiiNyzrn46utT+AjYTDCfwl1Rz28D6pyb2e3p1YUbABg7uDvjhvRIcTTOOVe3+voUVgArgNdbLpz2Z15hCZf9YxYA931vXIqjcc65+tXXfPS2mX1FUjEQfUmqADMzP+VtwLqSnVz88EwAHr14PN07Z6c4Iuecq199zUfHhf/6ZTJN9Mt/L6RoWzmP//AIjtyvZ6rDcc65BtV59VHUXcwDgUwzqwaOBC4FOrdAbG3a87PX8vriDZw9fpAnBOdcm5HIJanPAyZpP+ARYDTwz6RG1caV7qrkV5MX0r1TB6772shUh+OccwlLJClEzKwS+DbwZzO7Auif3LDatt+8uIitOyv5+/nj6OH9CM65NiSRpFAl6UzgfODF8DmfDaYes1YVA3D4kO4NlHRx69mFAAATaElEQVTOudYl0TuajyMYOnu5pKHA48kNq+36dMM2lhVt56xxA/2uZedcm9Pg0NlmtkDST4BhkkYBS83st8kPrW268fkFAFx14ogUR+Kcc43XYFKQdAzwKLCW4B6FvpLON7P3kx1cW7Ni03amr9jC/vvk07drbqrDcc65Rktkkp3bgZPNbBGApNEEScJvz41SvL2Ck25/G4Br/Yoj51wblUifQnZNQgAws8WAX1IT48H3V1BZbdx46hiOG9k71eE451yTJJIUPpb0d0lHh393k+CAeJImSloiaamk6+spd4Ykk9Qmax9mxr3vLqdrxw5cfPTQVIfjnHNNlkhSuAxYBvwU+H/AcoK7muslKZNgdNWvA2OAsyWNiVOuC/ATYHriYbcuU5cUsasywmkH90t1KM45t1fq7VOQdCCwH/Ccmd3ayG2PJ7hSaXm4rSeA04FFMeV+DdwKXNvI7bcaf3htCQA/P3l0iiNxzrm9U2dNQdLPCYa4OBf4j6R4M7DVpz+wJmq5kJg7oSUdCgw0sxeph6RLJM2UNLOoqKiRYSTXmi07WLiulBPH9KFTdiL99s4513rV13x0LnCQmZ0JHA78qJHbjnfnVu0Q3JIyCK5suqahDZnZvWY2zszG9erVq5FhJNezH68F4JqT/L4E51zbV19SKDez7QBmVtRA2XgKCUZYrTEAWBe13AU4AJgqaSVwBDC5LXU2byjdxe2vf0pBXjYj+3RJdTjOObfX6mvv2DdqbmYB+0XP1Wxm325g2zOA4eGwGGsJ5ns+J+r1W4maq0HSVOBaM5vZqCNIod++tBiAOyYd6kNaOOfahfqSwndilu9szIbNrErS5cCrQCbwgJktlHQzMNPMJjcu1NbFzHhv6SYAny/BOddu1DdH8xt7u3EzmwJMiXnul3WUnbC3+2tJry5cz5btFfzqtDFeS3DOtRuN7SdwobvfXk5BXjbnHTE41aE451yz8aTQBIvWlTJ3TQkTRvamQ6a/hc659iPhXzRJOckMpC3529SlAPz38cNTHIlzzjWvBpOCpPGS5gOfhcsHS/pr0iNrpTZu28WL8z7n4IHdGNijU6rDcc65ZpVITeEO4FRgM4CZzSWYiS0t/XP6agBuOm2PYZycc67NSyQpZJjZqpjnqpMRTGtXVR3hz69/xsg+XTh0kM+/7JxrfxIZrGeNpPGAhSOfXgF8mtywWqcH318JwOmH7pPaQJxzLkkSqSn8CLgaGARsIBiOorHjILV5kYhx19Sl5GRlcOmx+6U6HOecS4oGawpmtpFgiIq0NnnuOkp2VHLVCSPIzPCb1Zxz7VODSUHS/xE1umkNM7skKRG1QmbGPW8vIzND/NdxXktwzrVfifQpvB71OBf4FrvPk9DuPTljDZ+s38akwweS5TerOefasUSaj56MXpb0KPCfpEXUCr3xyUYAfn6Kz6zmnGvfmnLaOxRImwF/dlZU859FGzhhdG/yczukOhznnEuqRPoUivmiTyED2AJcn8ygWpMHP1gBwJnjBjZQ0jnn2r56k4KCMaEPJpgkByBiZnt0Ordnt76yhH0LOnPSmD6pDsU555Ku3uajMAE8Z2bV4V9aJYSlG8sAOGn/vj5ngnMuLSTSp/CRpMOSHkkr9MysQgBO2t9rCc659FBn85GkLDOrAo4GfihpGbCdYL5mM7N2nSjMjCdmBIPfHTqwW4qjcc65llFfn8JHwGHAN1sollblzU821t7B7E1Hzrl0UV9SEICZLWuhWFqVl+Z9DsDFxwxNcSTOOddy6ksKvSRdXddKM/tTEuJpFT7fupNnZ6/lrHEDyctJ5KZv55xrH+r7xcsE8ghrDOnk4Q+C6SPOPzJt7tFzzjmg/qTwuZnd3GKRtBLVkWDwu/FDenBA/66pDsc551pUfZekpl0NAeC52cF9eqcd4hPpOOfST31J4fgWi6IVeeKj1fTJz+Hc8YNSHYpzzrW4OpOCmW1pyUBag/KqamauKuZLQ3uS4RPpOOfSkE8OEGXWqmIAjh5WkOJInHMuNTwpRJk8Zx0Ax4zwpOCcS0+eFKI8P2cthw/pTr+uHVMdinPOpYQnhdCuymp2VUYYWtA51aE451zKJDUpSJooaYmkpZL2mJhH0tWSFkmaJ+kNSSm7W2z+2q0AHDjAB79zzqWvpCUFSZnAXcDXgTHA2ZLGxBSbDYwzs4OAZ4BbkxVPQ975tAiAUw/sl6oQnHMu5ZJZUxgPLDWz5WZWATwBnB5dwMzeMrMd4eI0YEAS46nXo9NWUZCXQ/fO2akKwTnnUi6ZSaE/sCZquTB8ri4XAy/HWyHpEkkzJc0sKipqxhADa0t2UrKjkgP65zf7tp1zri1JZlKId/dX3Ok8JZ0HjANui7fezO41s3FmNq5Xr17NGGLglQXrAfjhMfs2+7adc64tSea40IXAwKjlAcC62EKSTgB+AXzFzMqTGE+dnptdSN/8XI7ar2cqdu+cc61GMmsKM4DhkoZKygYmAZOjC0g6FPg78A0z25jEWOpkZixZv40++Tk+w5pzLu0lLSmE8ztfDrwKLAaeMrOFkm6W9I2w2G0EczY8LWmOpMl1bC5pHpu+mspq42wfAM8555LafISZTQGmxDz3y6jHJyRz/4mYXxjcn/CdsSm78Mk551qNtL6j2cx4dnYhR+zbgw6Zaf1WOOcckOZJYeG6UiqrjdH9/FJU55yDNE8K//xoNQBnjh3YQEnnnEsP6Z0Upq8mt0MGo/t1SXUozjnXKqRtUqiOBPfRjR/a0y9Fdc65UNomhY9XB7OsnTi6d4ojcc651iNtk0LNpajHDG/+YTOcc66tStuk8PriDQAM7NEpxZE451zrkbZJ4YNlmxnRJ4/MDO9PcM65GmmZFHZUVAEwdnD3FEfinHOtS1omhaUbywD48rCCFEfinHOtS1omhQ+XbQZgeG+/P8E556KlZVJYsmEbAIN7eiezc85FS8ukULKjkoK8bHI7ZKY6FOeca1XSLilUR4xF60q9k9k55+JIu6SwrmQn60t3MW5wj1SH4pxzrU7aJYX5a4M7mQd075jiSJxzrvVJu6SwZH3QyTx+qNcUnHMuVtolhalLNgLQo3N2iiNxzrnWJ+2SwrZdVWRnZvhw2c45F0faJYXMDDGib16qw3DOuVYp7ZLC8k3bOWyQX47qnHPxpFVSKN1VSXXE6NbJ+xOccy6etEoKNQPh9ejUIcWROOdc65RWSWF7eTBk9uh++SmOxDnnWqe0SgqbysoBKOiSk+JInHOudUqrpLBleyUAPbxPwTnn4kqrpPDxqmIAunmfgnPOxZVWSWHBuq30yc/xG9ecc64OaZUUVm3ewdCCzqkOwznnWq20SQo1Vx4NLfC7mZ1zri5JTQqSJkpaImmppOvjrM+R9GS4frqkIcmKZfWWHQCM7ufzMjvnXF2SlhQkZQJ3AV8HxgBnSxoTU+xioNjMhgG3A79PVjwfrw46mb35yDnn6pbMmsJ4YKmZLTezCuAJ4PSYMqcDD4ePnwGOV5J6gcsrIwDsv0/XZGzeOefahWQmhf7AmqjlwvC5uGXMrArYCvSM3ZCkSyTNlDSzqKioScEM6N6Rk8b0oWtHvxzVOefqkpXEbcc747cmlMHM7gXuBRg3btwe6xNx0v59OWn/vk15qXPOpY1k1hQKgYFRywOAdXWVkZQFdAW2JDEm55xz9UhmUpgBDJc0VFI2MAmYHFNmMnBB+PgM4E0za1JNwDnn3N5LWvORmVVJuhx4FcgEHjCzhZJuBmaa2WTgfuBRSUsJagiTkhWPc865hiWzTwEzmwJMiXnul1GPdwFnJjMG55xziUubO5qdc841zJOCc865Wp4UnHPO1fKk4Jxzrpba2hWgkoqAVU18eQGwqRnDaQv8mNODH3N62JtjHmxmvRoq1OaSwt6QNNPMxqU6jpbkx5we/JjTQ0scszcfOeecq+VJwTnnXK10Swr3pjqAFPBjTg9+zOkh6cecVn0Kzjnn6pduNQXnnHP18KTgnHOuVrtMCpImSloiaamk6+Osz5H0ZLh+uqQhLR9l80rgmK+WtEjSPElvSBqcijibU0PHHFXuDEkmqc1fvpjIMUv6bvhZL5T0z5aOsbkl8N0eJOktSbPD7/fJqYizuUh6QNJGSQvqWC9Jd4TvxzxJhzVrAGbWrv4IhuleBuwLZANzgTExZX4M3BM+ngQ8meq4W+CYjwM6hY9/lA7HHJbrArwDTAPGpTruFvichwOzge7hcu9Ux90Cx3wv8KPw8RhgZarj3stjPhY4DFhQx/qTgZcJZq48ApjenPtvjzWF8cBSM1tuZhXAE8DpMWVOBx4OHz8DHC8p3tSgbUWDx2xmb5nZjnBxGsFMeG1ZIp8zwK+BW4FdLRlckiRyzD8E7jKzYgAz29jCMTa3RI7ZgPzwcVf2nOGxTTGzd6h/BsrTgUcsMA3oJqlfc+2/PSaF/sCaqOXC8Lm4ZcysCtgK9GyR6JIjkWOOdjHBmUZb1uAxSzoUGGhmL7ZkYEmUyOc8Ahgh6X1J0yRNbLHokiORY74JOE9SIcH8LVe0TGgp09j/742S1El2UiTeGX/sdbeJlGlLEj4eSecB44CvJDWi5Kv3mCVlALcDF7ZUQC0gkc85i6AJaQJBbfBdSQeYWUmSY0uWRI75bOAhM/ujpCMJZnM8wMwiyQ8vJZL6+9UeawqFwMCo5QHsWZ2sLSMpi6DKWV91rbVL5JiRdALwC+AbZlbeQrElS0PH3AU4AJgqaSVB2+vkNt7ZnOh3+99mVmlmK4AlBEmirUrkmC8GngIwsw+BXIKB49qrhP6/N1V7TAozgOGShkrKJuhInhxTZjJwQfj4DOBNC3tw2qgGjzlsSvk7QUJo6+3M0MAxm9lWMyswsyFmNoSgH+UbZjYzNeE2i0S+288TXFSApAKC5qTlLRpl80rkmFcDxwNIGk2QFIpaNMqWNRn4XngV0hHAVjP7vLk23u6aj8ysStLlwKsEVy48YGYLJd0MzDSzycD9BFXMpQQ1hEmpi3jvJXjMtwF5wNNhn/pqM/tGyoLeSwkec7uS4DG/CpwkaRFQDVxnZptTF/XeSfCYrwH+T9JVBM0oF7blkzxJjxM0/xWE/SS/AjoAmNk9BP0mJwNLgR3ARc26/zb83jnnnGtm7bH5yDnnXBN5UnDOOVfLk4JzzrlanhScc87V8qTgnHOulicF1ypIqpY0J+pvSD1lh9Q1gmQj9zk1HH1zbjgsxMgmbOMySd8LH18oaZ+odfdJGtPA6z8I/x0i6ZxG7nuCpK3h6KCfSPpDAq85pK2PIuqSy5OCay12mtkhUX8rW2i/55rZwQQDJN7W2Beb2T1m9ki4eCGwT9S6H5jZogZef1T4cAjQqKQQetfMDgUOBU6V9OUGyh9CcI27c3F5UnCtVnj2/K6kj8O/o+KU2V/SR2HtYp6k4eHz50U9/3dJmQ3s7h1gWPja48Oz7/nh2PY54fO36Is5Kf4QPneTpGslnUEwptRj4T47hjWRcZJ+JOnWqJgvlPTX8HFZ+PQtwDHha68Kj/uQqNe8L+mguoI3s53AHMKB0SSNl/RBeBwfSBoZ3hF8M3BWuJ+zJHUOj3FGWDbeSLMunaR67HD/8z8zg+Du2znh33Phc52A3PDxcII7WCE4q14QPv4rwdk+BOPtdwRGAy8AHcLn/wZ8L84+pxLOsQBcBzxJMETCGmBE+PwjwJVAD4JxhGpu+OwW/nsTcG3s9qKXgV4Ewz/XPP8ycHT4uCz8dwLwYlSZC4A/h49H1Bx7TPy1rwG6A7OAvuFyPpAVPj4B+Ff4+ELgzqht/A44r+aYgE+Bzqn+Pvhf6v7a3TAXrs3aaWaHxDzXAbgzPGOuJvhxjPUh8AtJA4BnzewzSccDY4EZ4ZAeHYG6xnt6TNJOYCXBkMsjgRVm9mm4/mHgv4A7CeZkuE/SS0DCw3GbWZGk5eE4NZ+F+3i/gZc9Ddwo6Trg+8BDdZQ7RtK8cJu3mNn68PmuwMNhzckIh0mI4yTgG5KuDZdzgUHA4oaPzLVHnhRca3YVsAE4mKCpc4+Jcszsn5KmA6cAr0r6AcHQwg+b2c8S2Me5FjVInqS482pYMAbPeIKB1yYBlwNfbcSxPAl8F/iEoCZU7/gyZrZD0n8IJlT5LkGNI553zexUSSOA9yQ9Z2ZzCCYXesvMvhV22k+t4/UCvmNmSxpxLK4d8z4F15p1BT63YFz88wkGRNuNpH2B5WZ2B8HokQcBbwBnSOodlumhxOek/gQYImlYuHw+8LakPKCrmU0haE6KrdUAbCMYsjueZ4FvEoz9/2SCr70PuAOYYWb1Du0e1mz+F/h/4VNdgbXh4wvr2c+rwBUKq1QKRtN1acyTgmvN/gZcIGkaQdPR9jhlzgIWSJoDjCKYpnARcAPwWti08h8goekKzWwXwaiTT0uaD0SAewh+SF8Mt/c2QS0m1kPAPTUdzTHbLQYWAYPN7KM4r50HVIWXx14VvmYWUAo8mEjsYZzHShpKMAXp/0p6n92T6VvAmJqOZoIaRQdgXniZ768T3Jdrp3yUVOdaqfCeh6nAKGu/s4i5VsZrCs61QuENcdOBX3hCcC3JawrOOedqeU3BOedcLU8KzjnnanlScM45V8uTgnPOuVqeFJxzztX6/zQakqYJqB/nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# get all probabilities into one variable\n",
    "rf_probs = pipe_rf.predict_proba(X_te)\n",
    "\n",
    "# roc_curve returns three arrays, false positivity rate, true positivity rate (recall) and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_true = y_te, y_score = rf_probs[:, 0], # positive class = Fail / 0\n",
    "                                pos_label = 0) \n",
    "\n",
    "# create DataFrame out of the three arrays\n",
    "roc_df = pd.DataFrame({\n",
    "    \"fpr\": fpr,\n",
    "    \"tpr\": tpr,\n",
    "    \"thresholds\": thresholds\n",
    "})\n",
    "\n",
    "# plot ROC curve \n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positivity Rate\")\n",
    "plt.ylabel(\"True Positivity Rate\")\n",
    "plt.title(\"ROC-Curve of True-Fail and Predict-Pass Problem\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here visually that the curve is similar to the logistic regression model. A good model with a high recall would have a curve towards the top left corner, which would result from having a high TPR with a low FPR at the same time. \n",
    "\n",
    "In this case, we can only reach high TPR while also having many false positive misclassifications, so our model definitely lacks the needed nuance. The false negative classifications would also drop logically if our model had a higher TPR rate as FNR can be deduced from the TPR by calculating: $\\text{FNR} = 1 - \\text{TPR}$.\n",
    "\n",
    "Let's see to what level we had to lower our probability threshold to receive at least 85% recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>0.378170</td>\n",
       "      <td>0.852282</td>\n",
       "      <td>0.141780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>0.378339</td>\n",
       "      <td>0.852282</td>\n",
       "      <td>0.141757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>0.378395</td>\n",
       "      <td>0.852282</td>\n",
       "      <td>0.141742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7853</th>\n",
       "      <td>0.378395</td>\n",
       "      <td>0.852453</td>\n",
       "      <td>0.141736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7854</th>\n",
       "      <td>0.378451</td>\n",
       "      <td>0.852453</td>\n",
       "      <td>0.141716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7855</th>\n",
       "      <td>0.378508</td>\n",
       "      <td>0.852453</td>\n",
       "      <td>0.141708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>0.378536</td>\n",
       "      <td>0.852453</td>\n",
       "      <td>0.141703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7857</th>\n",
       "      <td>0.378536</td>\n",
       "      <td>0.852624</td>\n",
       "      <td>0.141701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7858</th>\n",
       "      <td>0.378592</td>\n",
       "      <td>0.852624</td>\n",
       "      <td>0.141697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>0.378592</td>\n",
       "      <td>0.852795</td>\n",
       "      <td>0.141686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fpr       tpr  thresholds\n",
       "7850  0.378170  0.852282    0.141780\n",
       "7851  0.378339  0.852282    0.141757\n",
       "7852  0.378395  0.852282    0.141742\n",
       "7853  0.378395  0.852453    0.141736\n",
       "7854  0.378451  0.852453    0.141716\n",
       "7855  0.378508  0.852453    0.141708\n",
       "7856  0.378536  0.852453    0.141703\n",
       "7857  0.378536  0.852624    0.141701\n",
       "7858  0.378592  0.852624    0.141697\n",
       "7859  0.378592  0.852795    0.141686"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_df[7850:7860]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, the difference between threshold changes and the effect on the TPR and FPR is slow and steady as the smoothness of our curve shows. \n",
    "\n",
    "To reach a TPR of in this random forest model, we would have to lower the probability threshold to around 14%. It is important to keep in mind that this is just a theoretical example that simplisticly created a binary problem out of a multi-class classification. In multi-clas problems, the final prediction is constantly affected by all other probability values. Changing the threshold here to 14% for the `Fail` class and thus classifying everything as `0` as soon as the probability hit that threshold would negatively affect all other classifications, so this is not a viable change on its own. \n",
    "\n",
    "All in all, this model got more biased in favor of the `Pass` class than the logistic regression. While we do reach 99% recall for class `Pass`, this doesn't help us in accurately determining final outcomes for students. The precision score for class `Pass` of 63% proves that. \n",
    "\n",
    "While the random forest models are better than our most-frequent baseline, a recall score of 1% for the `Fail` class and a recall score of 17% for the `Withdrawn` class show that the model significantly lacks prediction power for the two classes where it is critical to not have majorities of false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recall scores in variables\n",
    "rf_recall_0 = 0.01\n",
    "rf_recall_1 = 0.17\n",
    "rf_recall_2 = 0.99\n",
    "rf_recall_3 = 0.19\n",
    "\n",
    "# create a DataFrame to store recall scores and save the file\n",
    "save_df_recall = pd.DataFrame({\n",
    "    \"classes\": [0, 1, 2, 3],\n",
    "    \"recall\": [rf_recall_0, rf_recall_1, rf_recall_2, rf_recall_3]})\n",
    "\n",
    "# save the df\n",
    "save_df_recall.to_csv(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/results/05-random-forest-recall-results.csv\",\n",
    "    index = False)\n",
    "\n",
    "# save roc_curve values in df\n",
    "roc_df.to_csv(\n",
    "    \"/Users/Ingo/Python Files/Capstone Project/results/05-random-forest-roc-results.csv\",\n",
    "    index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame to store our the test accuracies and save the file\n",
    "save_df = pd.DataFrame({\n",
    "    \"model\": [\"rf\", \"rf_b\", \"rf_j\"],\n",
    "    \"test_accuracy\": [rf_acc, rf_acc_b, rf_acc_j]})\n",
    "\n",
    "# save the df\n",
    "save_df.to_csv(\"/Users/Ingo/Python Files/Capstone Project/results/05-random-forest-results.csv\",\n",
    "              index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
